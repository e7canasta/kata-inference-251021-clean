# Gu√≠a de Handlers y Listeners en InferencePipeline

## üéØ Resumen R√°pido

| Handler | Prop√≥sito | Cu√°ndo Usarlo |
|---------|-----------|---------------|
| **`status_update_handlers`** | Eventos de estado del pipeline | Errores, conexiones, warnings |
| **`watchdog`** | M√©tricas de rendimiento | Latencia, FPS, profiling |
| **`on_pipeline_start/end`** | Inicio/fin del pipeline | Logging, setup, cleanup |

---

## 1Ô∏è‚É£ `status_update_handlers` - Eventos del Pipeline

### ¬øQu√© es?
Lista de funciones callback que reciben objetos `StatusUpdate` cuando ocurren eventos en el pipeline.

### ¬øQu√© informaci√≥n recibo?
```python
StatusUpdate(
    timestamp=datetime,      # Cu√°ndo ocurri√≥
    severity=UpdateSeverity, # DEBUG, INFO, WARNING, ERROR
    event_type=str,          # Tipo de evento
    payload=dict,            # Datos adicionales
    context=str             # Contexto adicional
)
```

### Tipos de eventos comunes:
- `SOURCE_CONNECTION_ATTEMPT_FAILED`
- `SOURCE_CONNECTION_LOST`
- `INFERENCE_RESULTS_DISPATCHING_ERROR`
- `INFERENCE_THREAD_STARTED`
- `INFERENCE_THREAD_FINISHED`
- `INFERENCE_COMPLETED`
- `INFERENCE_ERROR`

### Casos de uso:
- ‚úÖ Detectar problemas de conexi√≥n
- ‚úÖ Logging de errores
- ‚úÖ Enviar alertas/notificaciones
- ‚úÖ Reintentar operaciones fallidas
- ‚úÖ Actualizar UI con estado del pipeline

### Ejemplo b√°sico:
```python
def my_status_handler(status: StatusUpdate) -> None:
    if status.severity == UpdateSeverity.ERROR:
        send_alert(f"Error en pipeline: {status.event_type}")
    
    if "CONNECTION" in status.event_type:
        log_connection_issue(status)

pipeline = InferencePipeline.init(
    ...,
    status_update_handlers=[my_status_handler]
)
```

---

## 2Ô∏è‚É£ `watchdog` (PipelineWatchDog) - M√©tricas de Rendimiento

### ¬øQu√© es?
Objeto que monitorea el rendimiento del pipeline (latencias, throughput, etc.)

### ¬øQu√© informaci√≥n recibo?
```python
PipelineStateReport(
    inference_throughput=float,           # FPS del pipeline
    latency_reports=[                     # Por cada source
        LatencyMonitorReport(
            source_id=int,
            frame_decoding_latency=float, # Tiempo de decodificaci√≥n
            inference_latency=float,      # Tiempo de inferencia
            e2e_latency=float,           # Latencia total
        )
    ],
    video_source_status_updates=[...],    # Hist√≥rico de updates
    sources_metadata=[...]                # Info de cada source
)
```

### Casos de uso:
- ‚úÖ Profiling del pipeline
- ‚úÖ Detectar cuellos de botella
- ‚úÖ Optimizar rendimiento
- ‚úÖ Dashboards de m√©tricas
- ‚úÖ An√°lisis de capacidad

### Implementaciones disponibles:
- `NullPipelineWatchdog` - No hace nada (default)
- `BasePipelineWatchDog` - Implementaci√≥n base con m√©tricas
- Custom - Puedes extender `BasePipelineWatchDog`

### Ejemplo b√°sico:
```python
from inference.core.interfaces.stream.watchdog import BasePipelineWatchDog

watchdog = BasePipelineWatchDog()

pipeline = InferencePipeline.init(
    ...,
    watchdog=watchdog
)

pipeline.start()

# En cualquier momento puedes obtener m√©tricas:
report = watchdog.get_report()
print(f"FPS: {report.inference_throughput}")
```

---

## 3Ô∏è‚É£ `on_pipeline_start` / `on_pipeline_end` - Lifecycle Hooks

### ¬øQu√© son?
Callbacks simples que se ejecutan al inicio y fin del pipeline.

### Casos de uso:
- ‚úÖ Logging de inicio/fin
- ‚úÖ Inicializar recursos externos
- ‚úÖ Cleanup de recursos
- ‚úÖ M√©tricas de tiempo total
- ‚úÖ Notificaciones de lifecycle

### Ejemplo:
```python
def on_start():
    logger.info("Pipeline iniciado")
    db.mark_pipeline_running()

def on_end():
    logger.info("Pipeline finalizado")
    db.mark_pipeline_stopped()

# NOTA: init() NO acepta estos par√°metros en modelos est√°ndar
# Solo est√°n disponibles en init_with_workflow() y init_with_custom_logic()
```

---

## üèóÔ∏è Arquitectura Recomendada

### Opci√≥n 1: Simple (solo status handlers)
```python
pipeline = InferencePipeline.init(
    ...,
    status_update_handlers=[my_handler]
)
```
**√ösalo cuando:** Solo necesitas saber qu√© est√° pasando (errores, conexiones)

### Opci√≥n 2: Con M√©tricas (watchdog)
```python
watchdog = BasePipelineWatchDog()
pipeline = InferencePipeline.init(
    ...,
    watchdog=watchdog,
    status_update_handlers=[my_handler]
)
```
**√ösalo cuando:** Necesitas optimizar rendimiento o dashboards

### Opci√≥n 3: Completo (todo integrado)
```python
class MyWatchdog(BasePipelineWatchDog):
    def on_status_update(self, status):
        # L√≥gica personalizada
        super().on_status_update(status)

watchdog = MyWatchdog()
pipeline = InferencePipeline.init(
    ...,
    watchdog=watchdog,
    status_update_handlers=[
        handler1,
        handler2,
        handler3,
    ]
)
```
**√ösalo cuando:** Aplicaci√≥n en producci√≥n con monitoreo completo

---

## üìã Checklist de Decisi√≥n

¬øQu√© necesito monitorear?

- [ ] **Errores de conexi√≥n** ‚Üí `status_update_handlers`
- [ ] **Warnings del pipeline** ‚Üí `status_update_handlers`
- [ ] **FPS/Throughput** ‚Üí `watchdog`
- [ ] **Latencia de inferencia** ‚Üí `watchdog`
- [ ] **Tiempo de decodificaci√≥n** ‚Üí `watchdog`
- [ ] **Setup inicial** ‚Üí `on_pipeline_start` (si disponible)
- [ ] **Cleanup final** ‚Üí `on_pipeline_end` (si disponible)

---

## üîç Debugging Tips

### Ver todos los eventos:
```python
def debug_handler(status: StatusUpdate):
    print(f"[{status.severity.name}] {status.event_type}")
    print(f"  Payload: {status.payload}")
```

### Ver solo errores cr√≠ticos:
```python
def error_handler(status: StatusUpdate):
    if status.severity == UpdateSeverity.ERROR:
        print(f"ERROR: {status.event_type}")
```

### M√©tricas cada N segundos:
```python
import time
from threading import Thread

def monitor(watchdog, interval=10):
    while True:
        time.sleep(interval)
        report = watchdog.get_report()
        print(f"FPS: {report.inference_throughput}")

Thread(target=monitor, args=(watchdog,), daemon=True).start()
```

---

## üìö Referencias

- `run_pipeline.py` - Ejemplo b√°sico con status_update_handlers
- `run_pipeline_with_watchdog.py` - Ejemplo completo con watchdog y monitoreo
- Documentaci√≥n Inference SDK: [inference.roboflow.com](https://inference.roboflow.com)

