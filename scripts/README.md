# Local ONNX Models - Quick Start

Este directorio contiene utilidades para exportar y usar modelos YOLO locales en formato ONNX.

## Ventajas de Modelos Locales

âœ… **Performance**: ~2-3x mÃ¡s rÃ¡pido que modelos de Roboflow
âœ… **Offline**: No requiere API key ni conexiÃ³n a internet
âœ… **OptimizaciÃ³n**: Modelos cuantizados especÃ­ficos para tu hardware

âŒ **Trade-off**: Requiere exportar modelos manualmente

## GuÃ­a RÃ¡pida

### 1. Exportar Modelos

```bash
# Desde la raÃ­z del proyecto
python scripts/export_onnx_models.py
```

Esto crearÃ¡:
- `models/yolo11n-320.onnx` (Nano - ultrafast, ~6MB)
- `models/yolo11s-320.onnx` (Small - balanced, ~22MB)
- `models/yolo11m-320.onnx` (Medium - accurate, ~50MB)

**Nota**: YOLO11 usa nomenclatura `yolo11n` (sin "v"), a diferencia de YOLOv8 que usa `yolov8n` (con "v")

### 2. Configurar Pipeline

Edita `config.yaml`:

```yaml
models:
  use_local: true
  local_path: "models/yolo11n-320.onnx"
  imgsz: 320
  confidence: 0.25
  iou_threshold: 0.45
```

### 3. Ejecutar Pipeline

```bash
# Con adaptive crop
python quickstart/inference/adeline/run_pipeline_mqtt.py
```

El pipeline detectarÃ¡ automÃ¡ticamente que estÃ¡s usando un modelo local y usarÃ¡ Ultralytics en lugar de Roboflow.

## Modelos Disponibles

| Modelo | TamaÃ±o | Velocidad | PrecisiÃ³n | Uso Recomendado |
|--------|--------|-----------|-----------|-----------------|
| yolo11n-320 | ~6MB | âš¡âš¡âš¡ | â­â­ | Dispositivos con recursos limitados |
| yolo11s-320 | ~22MB | âš¡âš¡ | â­â­â­ | Balance general (recomendado) |
| yolo11m-320 | ~50MB | âš¡ | â­â­â­â­ | Cuando precisiÃ³n es crÃ­tica |

## Detalles TÃ©cnicos

### Formato de ExportaciÃ³n

- **Formato**: ONNX (Open Neural Network Exchange)
- **PrecisiÃ³n**: FP32 (full precision)
- **TamaÃ±o imagen**: 320x320 (configurable)
- **SimplificaciÃ³n**: SÃ­ (grafo ONNX optimizado)
- **DinÃ¡mico**: No (tamaÃ±o fijo para mejor performance)

### Arquitectura de IntegraciÃ³n

```
Pipeline Flow:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PipelineConfig                      â”‚
â”‚  - use_local: true                  â”‚
â”‚  - local_path: models/yolov11n.onnx â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ get_model_from_config()             â”‚
â”‚  â””â”€> LocalONNXModel (Ultralytics)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AdaptiveInferenceHandler            â”‚
â”‚  - model: LocalONNXModel            â”‚
â”‚  - process_fn: process_frame_...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ adaptive_roi_inference()            â”‚
â”‚  â””â”€> process_frame_with_local_...() â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YOLO(model.onnx).predict()          â”‚
â”‚  â””â”€> sv.Detections.from_ultralytics â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
     Roboflow-compatible format
```

### ConversiÃ³n de Resultados

El adaptador `local_models.py` convierte automÃ¡ticamente:

**Ultralytics â†’ Supervision â†’ Roboflow Format**

```python
# Ultralytics YOLO prediction
results = model.predict(image)

# â†’ Supervision Detections
detections = sv.Detections.from_ultralytics(results[0])

# â†’ Roboflow-compatible dict
{
    'predictions': [
        {
            'x': center_x,
            'y': center_y,
            'width': w,
            'height': h,
            'confidence': conf,
            'class': class_name,
            'class_id': class_id,
        },
        ...
    ],
    'image': {'width': w, 'height': h},
}
```

Esto garantiza compatibilidad total con:
- VisualizaciÃ³n (`visualization.py`)
- ROI adaptativo (`adaptive_roi.py`)
- MQTT data plane (`mqtt_bridge.py`)

## Troubleshooting

### Error: "Modelo no encontrado"

```bash
# Verifica que el modelo existe
ls -lh models/

# Re-exporta si es necesario
python scripts/export_onnx_models.py
```

### Error: "ROBOFLOW_API_KEY not found"

Si usas modelos locales, no necesitas API key. AsegÃºrate de configurar:

```yaml
models:
  use_local: true
```

### Performance no mejora

1. Verifica que estÃ¡s usando el modelo local:
   - Logs deben mostrar: "ðŸ”§ Usando modelo local: yolov11n-320.onnx"

2. Considera usar un modelo mÃ¡s pequeÃ±o:
   - yolov11n-320 es el mÃ¡s rÃ¡pido

3. Habilita adaptive crop para mayor speedup:
   ```yaml
   adaptive_crop:
     enabled: true
   ```

## PrÃ³ximos Pasos

### CuantizaciÃ³n INT8 (TODO)

Para aÃºn mejor performance, exportar con cuantizaciÃ³n INT8:

```python
# En export_onnx_models.py
model.export(
    format="onnx",
    half=True,  # FP16
    int8=True,  # INT8 quantization
)
```

**Nota**: Requiere calibraciÃ³n dataset. Ver [Ultralytics Export Docs](https://docs.ultralytics.com/modes/export/)

### Custom Models

Para usar tus propios modelos entrenados:

1. Entrena modelo con Ultralytics o Roboflow
2. Exporta a ONNX:
   ```python
   from ultralytics import YOLO
   model = YOLO("path/to/your/model.pt")
   model.export(format="onnx", imgsz=320)
   ```
3. Coloca en `models/` y actualiza `config.yaml`
