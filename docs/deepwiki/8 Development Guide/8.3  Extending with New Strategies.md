# Extending with New Strategies

Relevant source files

- [adeline/CLAUDE.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md)
- [adeline/DESIGN.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md)
- [adeline/config.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py)

## Purpose and Scope

This document provides a tutorial for developers who want to extend the Adeline inference system with new ROI (Region of Interest) strategies or new detection stabilization strategies. The system uses the **Factory Pattern** to enable runtime selection of strategies through configuration, making it straightforward to add new implementations without modifying existing code.

**Scope of this document:**

- Adding new ROI strategy implementations (e.g., motion-based ROI, AI-guided ROI)
- Adding new stabilization strategy implementations (e.g., Kalman filtering, ensemble methods)
- Integrating new strategies with the configuration system
- Registering strategies in factory functions

**Related documentation:**

- For understanding the existing ROI strategies, see [ROI Strategies](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.5-roi-strategies)
- For understanding the existing stabilization strategies, see [Detection Stabilization](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.6-detection-stabilization)
- For overall factory pattern design principles, see [Factory Pattern for Strategies](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/4.2-factory-pattern-for-strategies)
- For module organization and where to place new files, see [Module Organization](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/8.1-module-organization)

---

## Strategy Architecture Overview

The Adeline system uses factory functions to create strategy objects based on configuration. This enables runtime behavior modification without code changes and makes the system easily extensible.

### Factory Pattern Implementation

**Sources:** [adeline/CLAUDE.md58-69](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L58-L69) [adeline/DESIGN.md24-34](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L24-L34) [adeline/config.py150-206](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L150-L206)

---

## Adding a New ROI Strategy

ROI strategies determine which portion of the video frame should be processed by the inference model. The system currently includes three strategies: `none` (full frame), `adaptive` (dynamic crop based on detections), and `fixed` (static region).

### File Structure for ROI Strategies

```
adeline/inference/roi/
├── __init__.py          # Factory: create_roi_strategy()
├── adaptive.py          # AdaptiveROIStrategy implementation
├── fixed.py             # FixedROIStrategy implementation
└── your_custom.py       # Your new strategy (add here)
```

### Step 1: Implement the Strategy Class

Create a new file `adeline/inference/roi/your_strategy_name.py`. The strategy must implement the interface expected by the `InferencePipeline`.

**Example: Implementing a center-weighted ROI strategy**

```
# adeline/inference/roi/center_weighted.py
"""
Center-Weighted ROI Strategy
Crops to center of frame with configurable dimensions.
"""
import numpy as np
from typing import Dict, Any, Optional

class CenterWeightedROIStrategy:
    """
    ROI strategy that crops to a fixed center region.
    
    Config parameters:
        - width_ratio: Width of ROI as fraction of frame width (0.0-1.0)
        - height_ratio: Height of ROI as fraction of frame height (0.0-1.0)
        - show_overlay: Whether to visualize ROI on output
    """
    
    def __init__(
        self,
        width_ratio: float = 0.6,
        height_ratio: float = 0.6,
        show_overlay: bool = True
    ):
        self.width_ratio = width_ratio
        self.height_ratio = height_ratio
        self.show_overlay = show_overlay
        self.roi_coords = None
    
    def compute_roi(self, frame: np.ndarray, detections: Optional[Any] = None) -> Dict[str, int]:
        """
        Compute center-weighted ROI coordinates.
        
        Args:
            frame: Input video frame
            detections: Not used in this strategy
            
        Returns:
            Dictionary with 'x_min', 'y_min', 'x_max', 'y_max' in pixel coordinates
        """
        h, w = frame.shape[:2]
        
        roi_w = int(w * self.width_ratio)
        roi_h = int(h * self.height_ratio)
        
        x_min = (w - roi_w) // 2
        y_min = (h - roi_h) // 2
        x_max = x_min + roi_w
        y_max = y_min + roi_h
        
        self.roi_coords = {
            'x_min': x_min,
            'y_min': y_min,
            'x_max': x_max,
            'y_max': y_max
        }
        
        return self.roi_coords
    
    def get_crop(self, frame: np.ndarray) -> np.ndarray:
        """
        Extract the ROI region from the frame.
        
        Args:
            frame: Input video frame
            
        Returns:
            Cropped frame region
        """
        if self.roi_coords is None:
            self.compute_roi(frame)
        
        return frame[
            self.roi_coords['y_min']:self.roi_coords['y_max'],
            self.roi_coords['x_min']:self.roi_coords['x_max']
        ]
    
    def visualize(self, frame: np.ndarray) -> np.ndarray:
        """
        Optionally draw ROI overlay on frame.
        
        Args:
            frame: Input frame to annotate
            
        Returns:
            Frame with ROI visualization
        """
        if not self.show_overlay or self.roi_coords is None:
            return frame
        
        import cv2
        frame_copy = frame.copy()
        cv2.rectangle(
            frame_copy,
            (self.roi_coords['x_min'], self.roi_coords['y_min']),
            (self.roi_coords['x_max'], self.roi_coords['y_max']),
            (0, 255, 0),
            2
        )
        return frame_copy
```

**Key interface requirements:**

- `compute_roi(frame, detections=None)` → returns ROI coordinates dictionary
- `get_crop(frame)` → returns cropped frame region
- Optional: `visualize(frame)` → returns annotated frame for display

**Sources:** [adeline/CLAUDE.md58-62](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L58-L62) [adeline/DESIGN.md24-34](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L24-L34)

### Step 2: Register in Factory Function

Edit `adeline/inference/roi/__init__.py` to register your new strategy in the factory function.

```
# adeline/inference/roi/__init__.py

from .adaptive import AdaptiveROIStrategy
from .fixed import FixedROIStrategy
from .center_weighted import CenterWeightedROIStrategy  # Import your strategy

def create_roi_strategy(config):
    """
    Factory function to create ROI strategy based on configuration.
    
    Args:
        config: PipelineConfig instance
        
    Returns:
        ROI strategy instance or None
    """
    mode = config.ROI_MODE.lower()
    
    if mode == 'none':
        return None  # No ROI processing
    
    elif mode == 'adaptive':
        return AdaptiveROIStrategy(
            margin=config.CROP_MARGIN,
            smoothing=config.CROP_SMOOTHING,
            # ... other params
        )
    
    elif mode == 'fixed':
        return FixedROIStrategy(
            x_min=config.FIXED_X_MIN,
            y_min=config.FIXED_Y_MIN,
            # ... other params
        )
    
    elif mode == 'center_weighted':  # Add your strategy
        return CenterWeightedROIStrategy(
            width_ratio=config.CENTER_WIDTH_RATIO,
            height_ratio=config.CENTER_HEIGHT_RATIO,
            show_overlay=config.CENTER_SHOW_OVERLAY
        )
    
    else:
        raise ValueError(f"Unknown ROI mode: {mode}")
```

**Sources:** [adeline/CLAUDE.md124-125](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L124-L125) [adeline/DESIGN.md26-30](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L26-L30)

### Step 3: Add Configuration Schema

Update `config/adeline/config.yaml.example` and `adeline/config.py` to support the new strategy parameters.

**In `config.yaml.example`:**

```
roi_strategy:
  mode: center_weighted  # Options: none, adaptive, fixed, center_weighted
  
  # Center-weighted ROI parameters
  center_weighted:
    width_ratio: 0.6      # Width as fraction of frame (0.0-1.0)
    height_ratio: 0.6     # Height as fraction of frame (0.0-1.0)
    show_overlay: true    # Visualize ROI rectangle
```

**In `adeline/config.py`:**

```
class PipelineConfig:
    def __init__(self, config_path: str = "config/adeline/config.yaml"):
        # ... existing code ...
        
        roi_strategy_cfg = config.get('roi_strategy', {})
        self.ROI_MODE = roi_strategy_cfg.get('mode', 'none').lower()
        
        # ... existing adaptive/fixed config ...
        
        # Center-weighted ROI parameters
        center_cfg = roi_strategy_cfg.get('center_weighted', {})
        self.CENTER_WIDTH_RATIO = center_cfg.get('width_ratio', 0.6)
        self.CENTER_HEIGHT_RATIO = center_cfg.get('height_ratio', 0.6)
        self.CENTER_SHOW_OVERLAY = center_cfg.get('show_overlay', True)
```

**Sources:** [adeline/config.py150-206](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L150-L206) [adeline/DESIGN.md38-48](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L38-L48)

### Step 4: Test Your Strategy

**Manual testing approach:**

1. Update your `config.yaml`:
    
    ```
    roi_strategy:
      mode: center_weighted
      center_weighted:
        width_ratio: 0.5
        height_ratio: 0.5
        show_overlay: true
    ```
    
2. Run the pipeline:
    
    ```
    python -m adeline
    ```
    
3. Verify behavior:
    
    - Check that detections are only reported within the center region
    - If `enable_visualization: true`, verify ROI rectangle is drawn
    - Monitor MQTT data plane for correct detection coordinates
4. Test runtime control (if ROI toggling is supported):
    
    ```
    python -m adeline.control.cli toggle_crop
    ```
    

**Sources:** [adeline/CLAUDE.md7-19](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L7-L19) [adeline/DESIGN.md38-48](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L38-L48)

---

## Adding a New Stabilization Strategy

Detection stabilization strategies filter detection results to reduce flickering and false positives. The system currently includes `none` (no filtering) and `temporal` (hysteresis-based filtering).

### File Structure for Stabilization Strategies

```
adeline/inference/stabilization/
├── __init__.py          # Strategy interface/base
├── core.py              # Factory: create_stabilization_strategy()
├── temporal.py          # TemporalStabilizationStrategy implementation
└── your_custom.py       # Your new strategy (add here)
```

### Step 1: Implement the Strategy Class

Create a new file `adeline/inference/stabilization/your_strategy_name.py`.

**Example: Implementing a confidence-threshold stabilization strategy**

```
# adeline/inference/stabilization/confidence_threshold.py
"""
Confidence Threshold Stabilization
Only reports detections above a threshold over multiple frames.
"""
from typing import List, Dict, Any
from collections import defaultdict

class ConfidenceThresholdStabilization:
    """
    Stabilization strategy that requires consistent high confidence.
    
    Config parameters:
        - threshold: Minimum confidence score (0.0-1.0)
        - required_frames: Number of consecutive frames above threshold
        - tracking_mode: 'class' or 'instance' (track by class name or bbox overlap)
    """
    
    def __init__(
        self,
        threshold: float = 0.6,
        required_frames: int = 3,
        tracking_mode: str = 'class'
    ):
        self.threshold = threshold
        self.required_frames = required_frames
        self.tracking_mode = tracking_mode
        
        # Track consecutive high-confidence frames per detection
        self.frame_counts = defaultdict(int)
        self.active_detections = {}
    
    def stabilize(self, detections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filter detections based on confidence stability.
        
        Args:
            detections: List of detection dictionaries with 'class', 'confidence', 'bbox', etc.
            
        Returns:
            Filtered list of stable detections
        """
        stable_detections = []
        current_keys = set()
        
        for det in detections:
            # Generate tracking key
            if self.tracking_mode == 'class':
                key = det['class']
            else:
                # Use bbox center for instance tracking
                bbox = det['bbox']
                center = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)
                key = f"{det['class']}_{int(center[0])}_{int(center[1])}"
            
            current_keys.add(key)
            
            # Check confidence threshold
            if det['confidence'] >= self.threshold:
                self.frame_counts[key] += 1
                
                # Only emit if seen enough times
                if self.frame_counts[key] >= self.required_frames:
                    stable_detections.append(det)
                    self.active_detections[key] = det
            else:
                # Below threshold, reset counter
                self.frame_counts[key] = 0
                if key in self.active_detections:
                    del self.active_detections[key]
        
        # Clean up detections not seen in this frame
        for key in list(self.frame_counts.keys()):
            if key not in current_keys:
                self.frame_counts[key] = max(0, self.frame_counts[key] - 1)
                if self.frame_counts[key] == 0 and key in self.active_detections:
                    del self.active_detections[key]
        
        return stable_detections
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Return statistics about stabilization state.
        
        Returns:
            Dictionary with tracking statistics
        """
        return {
            'active_detections': len(self.active_detections),
            'tracked_objects': list(self.active_detections.keys()),
            'frame_counts': dict(self.frame_counts),
            'config': {
                'threshold': self.threshold,
                'required_frames': self.required_frames,
                'tracking_mode': self.tracking_mode
            }
        }
```

**Key interface requirements:**

- `stabilize(detections)` → returns filtered detection list
- Optional: `get_stats()` → returns diagnostic information

**Sources:** [adeline/CLAUDE.md64-69](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L64-L69) [adeline/DESIGN.md24-34](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L24-L34)

### Step 2: Register in Factory Function

Edit `adeline/inference/stabilization/core.py` to register your strategy.

```
# adeline/inference/stabilization/core.py

from .temporal import TemporalStabilizationStrategy
from .confidence_threshold import ConfidenceThresholdStabilization

def create_stabilization_strategy(config):
    """
    Factory function to create stabilization strategy based on configuration.
    
    Args:
        config: PipelineConfig instance
        
    Returns:
        Stabilization strategy instance or None
    """
    mode = config.STABILIZATION_MODE.lower()
    
    if mode == 'none':
        return None  # No stabilization
    
    elif mode == 'temporal':
        return TemporalStabilizationStrategy(
            min_frames=config.STABILIZATION_MIN_FRAMES,
            max_gap=config.STABILIZATION_MAX_GAP,
            appear_confidence=config.STABILIZATION_APPEAR_CONF,
            persist_confidence=config.STABILIZATION_PERSIST_CONF
        )
    
    elif mode == 'confidence_threshold':  # Add your strategy
        return ConfidenceThresholdStabilization(
            threshold=config.CONFIDENCE_THRESHOLD,
            required_frames=config.CONFIDENCE_REQUIRED_FRAMES,
            tracking_mode=config.CONFIDENCE_TRACKING_MODE
        )
    
    else:
        raise ValueError(f"Unknown stabilization mode: {mode}")
```

**Sources:** [adeline/CLAUDE.md125-126](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L125-L126) [adeline/DESIGN.md26-30](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L26-L30)

### Step 3: Add Configuration Schema

**In `config.yaml.example`:**

```
detection_stabilization:
  mode: confidence_threshold  # Options: none, temporal, confidence_threshold
  
  # Confidence threshold stabilization parameters
  confidence_threshold:
    threshold: 0.6          # Minimum confidence score
    required_frames: 3      # Consecutive frames above threshold
    tracking_mode: class    # Options: class, instance
```

**In `adeline/config.py`:**

```
class PipelineConfig:
    def __init__(self, config_path: str = "config/adeline/config.yaml"):
        # ... existing code ...
        
        stabilization_cfg = config.get('detection_stabilization', {})
        self.STABILIZATION_MODE = stabilization_cfg.get('mode', 'none').lower()
        
        # ... existing temporal config ...
        
        # Confidence threshold stabilization parameters
        confidence_cfg = stabilization_cfg.get('confidence_threshold', {})
        self.CONFIDENCE_THRESHOLD = confidence_cfg.get('threshold', 0.6)
        self.CONFIDENCE_REQUIRED_FRAMES = confidence_cfg.get('required_frames', 3)
        self.CONFIDENCE_TRACKING_MODE = confidence_cfg.get('tracking_mode', 'class')
```

**Sources:** [adeline/config.py133-148](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L133-L148) [adeline/DESIGN.md38-48](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L38-L48)

### Step 4: Test Your Strategy

**Manual testing approach:**

1. Update `config.yaml`:
    
    ```
    detection_stabilization:
      mode: confidence_threshold
      confidence_threshold:
        threshold: 0.7
        required_frames: 2
        tracking_mode: class
    ```
    
2. Run the pipeline:
    
    ```
    python -m adeline
    ```
    
3. Verify behavior:
    
    - Check that only high-confidence detections appear
    - Verify detections persist after threshold is met
    - Query stabilization statistics:
        
        ```
        python -m adeline.control.cli stabilization_stats
        ```
        
4. Monitor MQTT data plane:
    
    ```
    python -m adeline.data.monitors data
    ```
    

**Sources:** [adeline/CLAUDE.md7-19](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L7-L19) [adeline/DESIGN.md38-48](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L38-L48)

---

## Integration with Pipeline Controller

The `InferencePipelineController` integrates strategies with the inference pipeline. Understanding this integration helps ensure your strategy works correctly within the system.

### Strategy Lifecycle

**Sources:** [adeline/CLAUDE.md39-42](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L39-L42) [adeline/DESIGN.md9-20](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L9-L20)

---

## Best Practices for Strategy Implementation

### Interface Compliance

|Strategy Type|Required Methods|Optional Methods|Return Types|
|---|---|---|---|
|ROI Strategy|`compute_roi(frame, detections=None)`|`visualize(frame)`, `get_crop(frame)`|`Dict[str, int]` with keys: `x_min`, `y_min`, `x_max`, `y_max`|
|Stabilization Strategy|`stabilize(detections)`|`get_stats()`, `reset()`|`List[Dict[str, Any]]` (same format as input)|

### Configuration Validation

Always provide sensible defaults and validate configuration parameters:

```
def __init__(self, threshold: float = 0.5, min_frames: int = 3):
    # Validate parameters
    if not 0.0 <= threshold <= 1.0:
        raise ValueError(f"threshold must be between 0.0 and 1.0, got {threshold}")
    if min_frames < 1:
        raise ValueError(f"min_frames must be >= 1, got {min_frames}")
    
    self.threshold = threshold
    self.min_frames = min_frames
```

### State Management

If your strategy maintains state (e.g., tracking history), implement proper cleanup:

```
class StatefulStrategy:
    def __init__(self):
        self.history = []
        self.frame_count = 0
    
    def reset(self):
        """Clear all accumulated state."""
        self.history.clear()
        self.frame_count = 0
    
    def stabilize(self, detections):
        self.frame_count += 1
        # Process detections...
        
        # Clean old history periodically
        if self.frame_count % 100 == 0:
            self._cleanup_old_history()
```

### Backward Compatibility

When modifying the factory or config schema, maintain backward compatibility:

```
def create_roi_strategy(config):
    mode = config.ROI_MODE.lower()
    
    # Support legacy mode names
    if mode == 'crop':  # Old name
        mode = 'adaptive'  # Map to new name
        logger.warning("'crop' mode is deprecated, use 'adaptive' instead")
    
    # ... rest of factory logic
```

**Sources:** [adeline/config.py176-206](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L176-L206) [adeline/DESIGN.md74-88](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L74-L88)

---

## Runtime Control Integration

If your strategy supports runtime reconfiguration, integrate with the MQTT control plane.

### Adding Commands for Your Strategy

To add a command that queries or modifies your strategy:

1. Add a callback in `adeline/control/plane.py`:
    
    ```
    def on_your_strategy_command(self, client, userdata, message):
        """Handle your_strategy_command from MQTT."""
        payload = json.loads(message.payload.decode())
        if self.on_your_strategy_callback:
            self.on_your_strategy_callback(payload)
    ```
    
2. Subscribe to the command topic in `MQTTControlPlane.connect()`:
    
    ```
    self.client.message_callback_add(
        f"{self.base_topic}/your_strategy",
        self.on_your_strategy_command
    )
    ```
    
3. Wire the callback in `InferencePipelineController`:
    
    ```
    def handle_your_strategy_command(self, payload):
        # Access your strategy instance
        strategy = self.roi_strategy  # or self.stabilization_strategy
        result = strategy.handle_command(payload)
        
        # Publish response
        self.control_plane.publish_status({
            'command': 'your_strategy',
            'result': result
        })
    
    # Register callback
    self.control_plane.on_your_strategy_callback = self.handle_your_strategy_command
    ```
    

**Sources:** [adeline/CLAUDE.md27-31](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L27-L31) [adeline/DESIGN.md9-20](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L9-L20)

---

## Summary Checklist

When adding a new strategy, ensure you complete these steps:

**For ROI Strategies:**

- [ ]  Create strategy class in `adeline/inference/roi/your_strategy.py`
- [ ]  Implement required methods: `compute_roi()`, `get_crop()`
- [ ]  Register in factory function: `adeline/inference/roi/__init__.py`
- [ ]  Add configuration parameters to `config.yaml.example`
- [ ]  Add config loading to `adeline/config.py`
- [ ]  Test with `python -m adeline`
- [ ]  Verify visualization (if applicable)
- [ ]  Test runtime control (if supporting `toggle_crop`)

**For Stabilization Strategies:**

- [ ]  Create strategy class in `adeline/inference/stabilization/your_strategy.py`
- [ ]  Implement required method: `stabilize()`
- [ ]  Implement optional method: `get_stats()`
- [ ]  Register in factory function: `adeline/inference/stabilization/core.py`
- [ ]  Add configuration parameters to `config.yaml.example`
- [ ]  Add config loading to `adeline/config.py`
- [ ]  Test with `python -m adeline`
- [ ]  Test `stabilization_stats` command
- [ ]  Monitor output via `python -m adeline.data.monitors data`

**General:**

- [ ]  Follow interface requirements for your strategy type
- [ ]  Validate configuration parameters
- [ ]  Provide sensible defaults
- [ ]  Add docstrings and comments
- [ ]  Consider backward compatibility
- [ ]  Update `config.yaml.example` with clear documentation

**Sources:** [adeline/CLAUDE.md58-69](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L58-L69) [adeline/DESIGN.md74-88](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L74-L88) [adeline/config.py22-51](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L22-L51)