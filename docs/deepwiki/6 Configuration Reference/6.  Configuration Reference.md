# Configuration Reference

Relevant source files

- [adeline/CLAUDE.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md)
- [adeline/config.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py)

## Purpose and Scope

This document provides a complete reference for configuring the Adeline inference system. It covers all configuration files, their formats, available options, and how configuration values flow through the system. This page focuses on the overall configuration architecture and loading mechanism.

For detailed information about specific configuration areas, see:

- Configuration file hierarchy and structure: [Configuration Hierarchy](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.1-configuration-hierarchy)
- Pipeline and inference settings: [Pipeline Settings](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.2-pipeline-settings)
- Model loading and management: [Model Management](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.3-model-management)
- MQTT broker and communication settings: [MQTT Configuration](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.4-mqtt-configuration)

For initial setup instructions, see [Configuration Setup](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/2.2-configuration-setup).

---

## Configuration Files Overview

The Adeline system uses a three-tier configuration architecture separating infrastructure, application settings, and sensitive credentials.

|File|Purpose|Location|Version Control|
|---|---|---|---|
|`config.yaml`|Pipeline settings, strategies, model config|`config/adeline/config.yaml`|`.gitignore` (use `.example` template)|
|`.env`|Sensitive credentials (API keys, passwords)|Project root|`.gitignore` (use `.example` template)|
|`docker-compose.mqtt.yml`|MQTT broker infrastructure|`config/adeline/docker-compose.mqtt.yml`|Committed to repository|
|`go2rtc.yaml`|RTSP proxy configuration|`config/adeline/go2rtc.yaml`|Committed to repository|
|`mosquitto.conf`|MQTT broker configuration|`config/adeline/mosquitto.conf`|Committed to repository|

**Sources:** [adeline/CLAUDE.md132-143](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L132-L143) [adeline/config.py59-75](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L59-L75)

---

## Configuration Loading Architecture

The following diagram shows how configuration is loaded from files and environment variables into the `PipelineConfig` object, which provides settings to all system components.

**Configuration Loading Sequence:**

1. `load_dotenv()` loads `.env` file into `os.environ` at module import time
2. `PipelineConfig.__init__()` reads `config.yaml` with `yaml.safe_load()`
3. Configuration values are validated and assigned to instance attributes
4. Components receive configuration through `PipelineConfig` instance

**Sources:** [adeline/config.py1-14](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L1-L14) [adeline/config.py56-128](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L56-L128)

---

## Critical Initialization Order

The configuration system enforces a critical initialization sequence to prevent `ModelDependencyMissing` warnings from heavy models that are not needed.

### The Model Disabling Pattern

### Why This Matters

The `inference` library checks environment variables during module import to determine which models to load. If a model is not disabled but its dependencies are missing, it emits `ModelDependencyMissing` warnings. Since some models (PALIGEMMA, FLORENCE2, SAM, etc.) have heavy dependencies, the system disables unused models by default.

**Implementation:**

The `disable_models_from_config()` function:

1. Reads `models_disabled.disabled` array from `config.yaml`
2. Sets `{MODEL}_ENABLED=False` in `os.environ` for each disabled model
3. **Must be called before importing the `inference` module**

**Sources:** [adeline/config.py22-51](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L22-L51) [adeline/CLAUDE.md46-49](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L46-L49) [adeline/CLAUDE.md106-109](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L106-L109)

---

## Configuration Class Structure

The `PipelineConfig` class ([adeline/config.py56-206](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L56-L206)) provides a strongly-typed interface to all configuration values. It loads settings from both YAML and environment variables, with environment variables taking precedence for sensitive values.

### PipelineConfig Attribute Categories

|Category|Attributes|Source|
|---|---|---|
|**Pipeline**|`RTSP_URL`, `MODEL_ID`, `MAX_FPS`, `ENABLE_VISUALIZATION`, `DISPLAY_STATISTICS`|`config.yaml`: `pipeline.*`|
|**Models**|`USE_LOCAL_MODEL`, `LOCAL_MODEL_PATH`, `MODEL_IMGSZ`, `MODEL_CONFIDENCE`, `MODEL_IOU_THRESHOLD`|`config.yaml`: `models.*`|
|**API Key**|`API_KEY`|`.env`: `ROBOFLOW_API_KEY`|
|**MQTT Broker**|`MQTT_BROKER`, `MQTT_PORT`, `MQTT_USERNAME`, `MQTT_PASSWORD`|`config.yaml`: `mqtt.broker.*` + `.env` overrides|
|**MQTT Topics**|`CONTROL_COMMAND_TOPIC`, `CONTROL_STATUS_TOPIC`, `DATA_TOPIC`, `METRICS_TOPIC`|`config.yaml`: `mqtt.topics.*`|
|**MQTT QoS**|`CONTROL_QOS`, `DATA_QOS`|`config.yaml`: `mqtt.qos.*`|
|**Logging**|`LOG_LEVEL`, `LOG_FORMAT`, `PAHO_LOG_LEVEL`|`config.yaml`: `logging.*`|
|**ROI Strategy**|`ROI_MODE`, `CROP_MARGIN`, `CROP_SMOOTHING`, `FIXED_X_MIN`, etc.|`config.yaml`: `roi_strategy.*`|
|**Stabilization**|`STABILIZATION_MODE`, `STABILIZATION_MIN_FRAMES`, `STABILIZATION_APPEAR_CONF`, etc.|`config.yaml`: `detection_stabilization.*`|

**Sources:** [adeline/config.py56-206](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L56-L206)

---

## Configuration Schema Overview

### YAML Structure (config.yaml)

The YAML configuration file follows this hierarchical structure:

```
pipeline:
  rtsp_url: string
  model_id: string
  max_fps: integer
  enable_visualization: boolean
  display_statistics: boolean

models:
  use_local: boolean
  local_path: string
  imgsz: integer
  confidence: float
  iou_threshold: float

models_disabled:
  disabled: [string array]

mqtt:
  broker:
    host: string
    port: integer
    username: string (optional, prefer .env)
    password: string (optional, prefer .env)
  topics:
    control_commands: string
    control_status: string
    data: string
    metrics: string
  qos:
    control: integer (0-2)
    data: integer (0-2)

roi_strategy:
  mode: "none" | "adaptive" | "fixed"
  adaptive: {...}
  fixed: {...}

detection_stabilization:
  mode: "none" | "temporal"
  temporal: {...}
  hysteresis: {...}

logging:
  level: string
  format: string
  paho_level: string
```

### Environment Variables (.env)

```
# Roboflow API (required if models.use_local: false)
ROBOFLOW_API_KEY=your_api_key_here

# MQTT Credentials (optional, can also be in config.yaml)
MQTT_USERNAME=your_username
MQTT_PASSWORD=your_password
```

**Sources:** [adeline/config.py77-128](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L77-L128) [adeline/config.py136-206](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L136-L206)

---

## Configuration Flow Diagram

This diagram shows how configuration values flow from files through `PipelineConfig` to specific system components and their code entities.

**Configuration Propagation:**

1. `PipelineConfig` loads and validates all settings
2. `InferencePipelineController` receives the config object
3. Controller passes relevant subsets to each component during initialization
4. Factory functions (`create_roi_strategy`, `create_stabilization_strategy`) receive config and create strategy instances
5. MQTT planes receive broker connection details and topic names

**Sources:** [adeline/config.py56-206](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L56-L206) [adeline/CLAUDE.md44-54](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L44-L54)

---

## Backward Compatibility

The configuration system supports backward compatibility for legacy configuration structures.

### Legacy ROI Configuration

The system recognizes the older `adaptive_crop.enabled` structure and automatically converts it to the new `roi_strategy.mode` format:

```
# Legacy format (still supported)
adaptive_crop:
  enabled: true
  margin: 0.2
  smoothing: 0.3

# Automatically converted to:
# roi_strategy.mode = "adaptive"
```

When legacy format is detected, a warning is logged recommending migration to the new structure.

**Sources:** [adeline/config.py177-205](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L177-L205)

---

## Configuration Validation

The `PipelineConfig` class performs validation during initialization:

### Required Fields Validation

- **API Key:** If `USE_LOCAL_MODEL` is `False`, `ROBOFLOW_API_KEY` must be set in `.env`
- **Config File:** `config.yaml` must exist at the specified path
- Raises `FileNotFoundError` or `ValueError` with descriptive error messages

### Default Values

If `config.yaml` is missing during `disable_models_from_config()`, a default set of heavy models is disabled:

```
default_disabled = [
    "PALIGEMMA", "FLORENCE2", "QWEN_2_5",
    "CORE_MODEL_SAM", "CORE_MODEL_SAM2", "CORE_MODEL_CLIP",
    "CORE_MODEL_GAZE", "SMOLVLM2", "DEPTH_ESTIMATION",
    "MOONDREAM2", "CORE_MODEL_TROCR", "CORE_MODEL_GROUNDINGDINO",
    "CORE_MODEL_YOLO_WORLD", "CORE_MODEL_PE",
]
```

**Sources:** [adeline/config.py68-100](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L68-L100) [adeline/config.py30-41](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L30-L41)

---

## Entry Point Configuration Usage

The main entry point demonstrates the critical initialization sequence:

```
__main__.py:
1. Import config module
2. Call disable_models_from_config()
3. NOW import inference module
4. Create PipelineConfig instance
5. Pass config to InferencePipelineController
6. Start the system
```

This pattern ensures models are disabled before the inference module's import-time checks occur.

**Sources:** [adeline/CLAUDE.md139-142](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L139-L142) [adeline/config.py22-51](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py#L22-L51)

---

## Summary

The Adeline configuration system provides:

1. **Three-tier architecture:** Infrastructure (Docker Compose), application (YAML), secrets (.env)
2. **Type-safe configuration:** `PipelineConfig` class with strongly-typed attributes
3. **Critical initialization order:** `disable_models_from_config()` before inference imports
4. **Hierarchical validation:** File existence, required fields, value types
5. **Backward compatibility:** Legacy configuration structures are automatically converted
6. **Environment variable precedence:** Sensitive values from `.env` override YAML
7. **Factory pattern integration:** Configuration drives strategy creation

For detailed configuration options by category, see the sub-pages:

- [Configuration Hierarchy](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.1-configuration-hierarchy)
- [Pipeline Settings](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.2-pipeline-settings)
- [Model Management](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.3-model-management)
- [MQTT Configuration](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6.4-mqtt-configuration)