# Multi-Sink Composition

Relevant source files

- [adeline/CLAUDE.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md)
- [adeline/DESIGN.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md)
- [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py)

## Purpose and Scope

This document explains the **multi-sink pattern** used in Adeline to direct inference output to multiple independent destinations without modifying the core pipeline logic. The pattern enables parallel processing of detection results for MQTT publishing, local visualization, and ROI feedback loops through functional composition.

For information about the overall system architecture, see [System Architecture](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/3-system-architecture). For details about specific sink implementations, see [Data Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.4-data-plane) (MQTT output) and [ROI Strategies](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.5-roi-strategies) (ROI updates).

## Concept and Rationale

The multi-sink pattern solves the problem of **fan-out**: sending the same inference results to multiple consumers without tight coupling. Instead of hardcoding multiple output paths into the pipeline, sinks are composed functionally using the `multi_sink` utility from the `inference` library.

### Key Benefits

|Benefit|Description|
|---|---|
|**Separation of Concerns**|Each sink handles one responsibility (MQTT, visualization, ROI update)|
|**Composability**|Sinks can be combined arbitrarily without modifying pipeline code|
|**Configuration-Driven**|Which sinks are active is controlled by `config.yaml`, not code|
|**Independent Failure**|One sink's failure doesn't affect others|
|**Extensibility**|New sinks can be added without touching existing ones|

**Sources:** [adeline/DESIGN.md63-73](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L63-L73) [adeline/CLAUDE.md113-121](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L113-L121)

## Architecture Overview

The following diagram shows how multi-sink composition fits into the inference pipeline architecture:

**Diagram: Multi-Sink Composition in Pipeline Architecture**

**Sources:** [adeline/app/controller.py32-39](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L32-L39) [adeline/app/controller.py213-234](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L213-L234)

## Sink Types

### MQTT Sink

The MQTT sink publishes detection results to the data plane for remote consumption.

**Purpose:** Distribute inference results to external systems via MQTT (QoS 0 for performance).

**Factory Function:** `create_mqtt_sink(data_plane)`

**Location:** [adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py)

**Usage Pattern:**

```
from adeline.data import create_mqtt_sink

mqtt_sink = create_mqtt_sink(self.data_plane)
```

**Sources:** [adeline/app/controller.py92](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L92-L92) [adeline/data/__init__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/__init__.py)

### Visualization Sink

The visualization sink displays annotated frames with detection boxes and optional ROI overlays using OpenCV.

**Purpose:** Provide local real-time visualization of inference results and pipeline state.

**Factory Function:** `create_visualization_sink(roi_state, inference_handler, display_stats, window_name)`

**Location:** [adeline/visualization/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/visualization/)

**Configuration Control:**

- Enabled when `pipeline.enable_visualization: true` in `config.yaml`
- Statistics overlay controlled by `pipeline.display_statistics: true`

**Usage Pattern:**

```
from adeline.visualization import create_visualization_sink

viz_sink = create_visualization_sink(
    roi_state=self.roi_state,
    inference_handler=self.inference_handler,
    display_stats=self.config.DISPLAY_STATISTICS,
    window_name="Inference Pipeline (Adaptive ROI)"
)
```

**Sources:** [adeline/app/controller.py221-232](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L221-L232) [adeline/app/controller.py256-261](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L256-L261)

### ROI Update Sink

The ROI update sink creates a feedback loop by updating the adaptive ROI state based on current detections.

**Purpose:** Enable dynamic ROI adjustment by feeding detection results back into the ROI strategy.

**Function:** `roi_update_sink(predictions, roi_state)`

**Location:** [adeline/inference/roi/__init__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/roi/__init__.py)

**Applicability:** Only used when `roi_strategy.mode: adaptive` in configuration.

**Usage Pattern:**

```
from functools import partial
from adeline.inference.roi import roi_update_sink

roi_sink = partial(roi_update_sink, roi_state=self.roi_state)
sinks_list.append(roi_sink)
```

**Note:** Fixed ROI mode does not use this sink because the ROI is static and immutable.

**Sources:** [adeline/app/controller.py216-219](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L216-L219) [adeline/inference/roi/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/roi/)

### Stabilization Sink

The stabilization sink wraps another sink (typically the MQTT sink) to filter detections through temporal and hysteresis logic before forwarding.

**Purpose:** Reduce detection flickering by requiring N consecutive frames to confirm a detection.

**Factory Function:** `create_stabilization_sink(stabilizer, downstream_sink)`

**Location:** [adeline/inference/stabilization/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/stabilization/)

**Configuration Control:** Enabled when `detection_stabilization.mode: temporal` in `config.yaml`.

**Usage Pattern:**

```
from adeline.inference.stabilization import create_stabilization_sink

# Wrap the MQTT sink with stabilization
mqtt_sink = create_mqtt_sink(self.data_plane)
mqtt_sink = create_stabilization_sink(
    stabilizer=self.stabilizer,
    downstream_sink=mqtt_sink
)
```

**Sources:** [adeline/app/controller.py95-120](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L95-L120)

## Composition Patterns

The following diagram shows different sink composition patterns based on pipeline mode and configuration:

**Diagram: Four Common Sink Composition Patterns**

### Pattern Selection Logic

The following table shows how configuration determines which pattern is used:

|Configuration|Pattern|Sinks Included|
|---|---|---|
|`roi_strategy.mode: none`  <br>`detection_stabilization.mode: none`|Pattern 1|MQTT, Visualization (optional)|
|`roi_strategy.mode: adaptive`  <br>`detection_stabilization.mode: none`|Pattern 2|MQTT, ROI Update, Visualization (optional)|
|`roi_strategy.mode: fixed`  <br>`detection_stabilization.mode: none`|Pattern 3|MQTT, Visualization (optional)|
|Any ROI mode  <br>`detection_stabilization.mode: temporal`|Pattern 4|Stabilization(MQTT), ROI Update (if adaptive), Visualization (optional)|

**Sources:** [adeline/app/controller.py131-276](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L131-L276)

## Implementation Details

### Sink Creation Sequence

The following sequence diagram shows how sinks are created and composed during pipeline initialization:

**Diagram: Sink Creation and Composition Sequence**

**Sources:** [adeline/app/controller.py68-276](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L68-L276)

### Code Structure

The following diagram maps the multi-sink pattern to concrete code entities:

**Diagram: Multi-Sink Code Entity Map**

**Sources:** [adeline/app/controller.py1-276](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L1-L276) [adeline/data/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/) [adeline/visualization/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/visualization/) [adeline/inference/roi/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/roi/) [adeline/inference/stabilization/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/stabilization/)

### Standard Pipeline Example

For pipelines without ROI strategies (standard mode), sink composition is simpler:

**Code Reference:** [adeline/app/controller.py254-264](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L254-L264)

```
# Standard pipeline: MQTT + optional visualization
if self.config.ENABLE_VISUALIZATION:
    viz_sink = create_visualization_sink(
        roi_state=None,
        inference_handler=None,
        display_stats=self.config.DISPLAY_STATISTICS,
        window_name="Inference Pipeline (Standard)"
    )
    on_prediction = partial(multi_sink, sinks=[mqtt_sink, viz_sink])
else:
    on_prediction = mqtt_sink

self.pipeline = InferencePipeline.init(
    # ... other params ...
    on_prediction=on_prediction,
)
```

### Adaptive ROI Pipeline Example

For pipelines with adaptive ROI, an additional ROI update sink creates a feedback loop:

**Code Reference:** [adeline/app/controller.py213-234](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L213-L234)

```
# Adaptive ROI pipeline: MQTT + ROI feedback + optional visualization
sinks_list = [mqtt_sink]

# Add ROI update sink for adaptive mode
if self.config.ROI_MODE == 'adaptive':
    roi_sink = partial(roi_update_sink, roi_state=self.roi_state)
    sinks_list.append(roi_sink)

if self.config.ENABLE_VISUALIZATION:
    viz_sink = create_visualization_sink(
        roi_state=self.roi_state,
        inference_handler=self.inference_handler,
        display_stats=self.config.DISPLAY_STATISTICS,
        window_name=f"Inference Pipeline ({self.config.ROI_MODE.capitalize()} ROI)"
    )
    sinks_list.append(viz_sink)

on_prediction = partial(multi_sink, sinks=sinks_list)
```

### Stabilization Wrapping Pattern

When stabilization is enabled, the MQTT sink is wrapped before composition:

**Code Reference:** [adeline/app/controller.py94-120](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L94-L120)

```
# Create base MQTT sink
mqtt_sink = create_mqtt_sink(self.data_plane)

# Wrap with stabilization if enabled
if self.config.STABILIZATION_MODE != 'none':
    from ..inference.stabilization import (
        create_stabilization_strategy,
        create_stabilization_sink,
    )
    
    self.stabilizer = create_stabilization_strategy(stab_config)
    
    # Wrap mqtt_sink with stabilization
    mqtt_sink = create_stabilization_sink(
        stabilizer=self.stabilizer,
        downstream_sink=mqtt_sink,
    )

# Now compose with other sinks
sinks_list = [mqtt_sink]  # Already wrapped if stabilization enabled
# ... add other sinks ...
```

**Sources:** [adeline/app/controller.py92-125](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L92-L125)

## Configuration-Driven Behavior

The multi-sink composition is entirely controlled by configuration, requiring no code changes to modify which sinks are active.

### Configuration Keys

|Configuration Key|Effect on Sink Composition|
|---|---|
|`pipeline.enable_visualization`|Adds/removes visualization sink|
|`pipeline.display_statistics`|Controls statistics overlay in visualization sink|
|`roi_strategy.mode`|`adaptive` adds ROI update sink; `fixed` or `none` omits it|
|`detection_stabilization.mode`|`temporal` wraps MQTT sink; `none` uses unwrapped sink|

### Example Configuration

**File:** `config/adeline/config.yaml`

```
pipeline:
  enable_visualization: true
  display_statistics: true

roi_strategy:
  mode: adaptive  # Adds ROI update sink

detection_stabilization:
  mode: temporal  # Wraps MQTT sink with stabilization
```

**Result:** Predictions flow through `multi_sink` to:

1. Stabilization-wrapped MQTT sink → MQTT Data Plane
2. ROI update sink → Adaptive ROI State
3. Visualization sink → OpenCV display

**Sources:** [adeline/config.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py) [adeline/app/controller.py59-67](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L59-L67)

## Extensibility

### Adding a New Sink

To add a new sink type:

1. **Create sink factory function** in appropriate module (e.g., `adeline/custom/sinks.py`)
2. **Add configuration option** in `config.yaml` to enable/disable the sink
3. **Import factory** in `controller.py`
4. **Add to composition logic** in `InferencePipelineController.setup()`

**Example:**

```
# In controller.py setup()
if self.config.ENABLE_CUSTOM_SINK:
    from ..custom import create_custom_sink
    custom_sink = create_custom_sink(self.config.CUSTOM_PARAM)
    sinks_list.append(custom_sink)
```

No changes to the pipeline, existing sinks, or multi-sink logic are required.

**Sources:** [adeline/DESIGN.md76-83](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L76-L83)

### Sink Requirements

A sink must be a callable with signature:

```
def sink_function(predictions: dict, video_frame: VideoFrame) -> None:
    # Process predictions and/or frame
    pass
```

The `multi_sink` utility handles calling each sink with the same arguments.

**Sources:** [adeline/CLAUDE.md113-121](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L113-L121)

## Summary

The multi-sink pattern provides:

- **Functional composition** of output destinations
- **Configuration-driven** sink activation
- **Independent failures** between sinks
- **Easy extensibility** for new output types
- **No pipeline modification** required to change outputs

This pattern is central to Adeline's design philosophy of **complexity by design**: the architecture handles complexity through well-defined composition patterns rather than through complex conditional logic.

**Sources:** [adeline/DESIGN.md1-116](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L1-L116) [adeline/CLAUDE.md96-121](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L96-L121)