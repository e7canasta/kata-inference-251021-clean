# Monitoring and Data Streams

Relevant source files

- [Makefile](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile)
- [README.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md)
- [adeline/CLAUDE.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md)

## Purpose and Scope

This document describes the monitoring infrastructure and data streams in the Adeline inference system. It covers the Data Plane architecture, available monitoring tools, data stream types, message formats, and how to consume data for external systems.

For information about sending control commands to the pipeline, see [Control Commands](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/7.2-control-commands). For details on the Data Plane component implementation, see [Data Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.4-data-plane). For infrastructure setup including the MQTT broker, see [Infrastructure Services](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/7.4-infrastructure-services).

---

## Monitoring Architecture Overview

The Adeline system separates monitoring concerns into two distinct streams:

1. **Data Stream (QoS 0)**: High-volume detection results, metrics, and optional full frames published via `MQTTDataPlane`
2. **Status Stream (QoS 1)**: Reliable pipeline state updates published via `MQTTControlPlane`

This separation ensures monitoring data does not interfere with control plane reliability, and control operations are not delayed by high-volume data traffic.

**Sources:** [adeline/CLAUDE.md23-37](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L23-L37) [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py) [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)

---

## Data Plane Publishing

The `MQTTDataPlane` class is responsible for publishing all inference data to MQTT topics. It uses **QoS 0 (fire-and-forget)** to prioritize throughput and minimize latency for high-frequency detection data.

### Key Components

|Component|Location|Purpose|
|---|---|---|
|`MQTTDataPlane`|[adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py)|Main data publishing client|
|`create_mqtt_sink()`|[adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py)|Factory function for creating MQTT sinks|
|`compose_detection_result()`|[adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py)|Formats detection data for MQTT|
|`compose_watchdog_metrics()`|[adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py)|Formats watchdog metrics for MQTT|

### Data Publishing Flow

**Sources:** [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py) [adeline/CLAUDE.md33-37](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L33-L37)

---

## Monitoring Tools

The system provides two built-in monitoring tools accessible via the `adeline.data.monitors` module.

### Entry Points

|Command|Description|Implementation|
|---|---|---|
|`python -m adeline.data.monitors`|Data monitor (default)|[adeline/data/monitors/\\_\\_main\\_\\_.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/monitors///_//_main//_//_.py)|
|`python -m adeline.data.monitors data`|Data monitor (explicit)|[adeline/data/monitors/\\_\\_main\\_\\_.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/monitors///_//_main//_//_.py)|
|`python -m adeline.data.monitors status`|Status monitor|[adeline/data/monitors/\\_\\_main\\_\\_.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/monitors///_//_main//_//_.py)|
|`make monitor-data`|Makefile alias for data monitor|[Makefile115-119](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L115-L119)|
|`make monitor-status`|Makefile alias for status monitor|[Makefile120-124](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L120-L124)|

### Data Monitor

The data monitor subscribes to detection and metrics topics, displaying real-time inference results.

```
# Start data monitor with verbose output
make monitor-data

# Or directly
python -m adeline.data.monitors data --verbose
```

**Key Features:**

- Subscribes to `inference/data/detections` (QoS 0)
- Subscribes to `inference/data/metrics` (QoS 0)
- Displays detection counts, confidence scores, and class names
- Shows watchdog metrics (FPS, processing time)
- Verbose mode for detailed JSON output

### Status Monitor

The status monitor subscribes to control plane status updates.

```
# Start status monitor
make monitor-status

# Or directly
python -m adeline.data.monitors status
```

**Key Features:**

- Subscribes to `inference/control/status` (QoS 1)
- Displays pipeline state changes (running, paused, stopped)
- Shows configuration updates
- Reliable delivery via QoS 1

**Sources:** [adeline/CLAUDE.md14-19](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L14-L19) [Makefile115-124](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L115-L124) [adeline/data/monitors/\\_\\_main\\_\\_.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/monitors///_//_main//_//_.py)

---

## Data Stream Types

### Detection Results Stream

Published to: `inference/data/detections` (QoS 0)

Contains complete inference results for each processed frame, including all detected objects, their bounding boxes, confidence scores, and class labels.

**Message Format:**

```
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "frame_id": 12345,
  "detections": [
    {
      "class": "person",
      "confidence": 0.92,
      "bbox": {
        "x_min": 120,
        "y_min": 340,
        "x_max": 280,
        "y_max": 560
      }
    }
  ],
  "detection_count": 1,
  "roi_applied": true,
  "stabilization_active": true
}
```

### Metrics Stream

Published to: `inference/data/metrics` (QoS 0)

Contains performance metrics from the inference watchdog, tracking pipeline throughput and processing efficiency.

**Message Format:**

```
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "fps": 28.5,
  "processing_time_ms": 35.2,
  "frame_count": 12345,
  "dropped_frames": 12,
  "model_inference_time_ms": 28.1,
  "queue_size": 2
}
```

### Status Updates Stream

Published to: `inference/control/status` (QoS 1)

Contains pipeline state transitions and configuration changes, published by the Control Plane for reliability.

**Message Format:**

```
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "status": "running",
  "message": "Pipeline resumed",
  "command_id": "abc-123",
  "roi_enabled": true,
  "stabilization_mode": "temporal"
}
```

**Sources:** [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)

---

## MQTT Topic Structure

**Topic Reference:**

|Topic|QoS|Direction|Purpose|
|---|---|---|---|
|`inference/control/commands`|1|→ Control Plane|Reliable command delivery|
|`inference/control/status`|1|← Control Plane|Reliable status updates|
|`inference/data/detections`|0|← Data Plane|High-volume detection results|
|`inference/data/metrics`|0|← Data Plane|Performance metrics|
|`inference/data/full_frames`|0|← Data Plane|Optional frame publishing|

**Sources:** [adeline/CLAUDE.md27-37](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L27-L37) [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)

---

## Consuming Data Streams

### Using Built-in Monitors

The simplest way to consume data is using the built-in monitoring tools:

```
# Monitor detection data with verbose JSON output
make monitor-data

# Monitor status updates only
make monitor-status
```

### Custom MQTT Subscribers

External systems can subscribe to any topic using standard MQTT clients. The broker runs on `localhost:1883` by default.

**Example: Python MQTT Client**

```
import paho.mqtt.client as mqtt
import json

def on_message(client, userdata, message):
    data = json.loads(message.payload.decode())
    print(f"Received on {message.topic}:")
    print(f"  Detections: {data.get('detection_count', 0)}")
    print(f"  FPS: {data.get('fps', 'N/A')}")

client = mqtt.Client()
client.on_message = on_message
client.connect("localhost", 1883)

# Subscribe to detection and metrics streams
client.subscribe("inference/data/detections", qos=0)
client.subscribe("inference/data/metrics", qos=0)

client.loop_forever()
```

### QoS Considerations

**QoS 0 (Data Streams):**

- Best-effort delivery, no acknowledgment
- Minimal overhead, maximum throughput
- Acceptable for high-frequency data where occasional loss is tolerable
- Used for: detections, metrics, full frames

**QoS 1 (Status Streams):**

- At-least-once delivery with acknowledgment
- Ensures critical state changes are received
- Small overhead for reliability
- Used for: status updates, command acknowledgments

**Sources:** [adeline/CLAUDE.md102-104](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L102-L104)

---

## Metrics Request Command

While metrics are published periodically, you can request immediate metrics via the control plane:

```
# Request current metrics
make metrics

# Or directly
python -m adeline.control.cli metrics
```

This command triggers immediate publication to `inference/data/metrics` rather than waiting for the next periodic update.

**Sources:** [Makefile100-102](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L100-L102) [adeline/control/cli.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py) [adeline/CLAUDE.md29](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L29-L29)

---

## Monitoring Configuration

The monitoring behavior can be configured in `config/adeline/config.yaml`:

```
mqtt:
  data_plane:
    broker: "localhost"
    port: 1883
    qos: 0
    topics:
      detections: "inference/data/detections"
      metrics: "inference/data/metrics"
      full_frames: "inference/data/full_frames"
    
    # Enable/disable full frame publishing (high bandwidth)
    publish_full_frames: false
    
    # Metrics publishing interval (seconds)
    metrics_interval: 5.0
```

**Configuration Options:**

|Option|Default|Description|
|---|---|---|
|`mqtt.data_plane.qos`|0|QoS level for all data topics|
|`mqtt.data_plane.publish_full_frames`|false|Enable full frame image publishing|
|`mqtt.data_plane.metrics_interval`|5.0|Seconds between metric publications|

**Sources:** [adeline/config.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py) [adeline/CLAUDE.md51-54](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L51-L54)

---

## Troubleshooting Monitoring

### No Data Received

**Check MQTT broker is running:**

```
make services-status
```

**Check pipeline is running:**

```
make status
```

**Verify topic subscriptions:**

```
# Use mosquitto_sub to test directly
mosquitto_sub -h localhost -p 1883 -t "inference/data/#" -v
```

### High Latency

- Data plane uses QoS 0 for minimal latency
- If monitoring clients are slow, consider:
    - Reducing `metrics_interval` in config
    - Disabling `publish_full_frames` (high bandwidth)
    - Running monitors on separate machines

### Missing Metrics

Metrics are published:

1. Periodically (every `metrics_interval` seconds)
2. On demand (via `make metrics` command)

If periodic metrics are missing, check the pipeline is actively processing frames.

**Sources:** [README.md180-199](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L180-L199) [Makefile130-151](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L130-L151)