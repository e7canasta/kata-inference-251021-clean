# Operations Guide

Relevant source files

- [Makefile](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile)
- [README.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md)
- [adeline/control/cli.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py)

This guide provides practical instructions for operating the Adeline inference system in production or development environments. It covers the complete operational lifecycle: starting services, running the pipeline, controlling execution, monitoring output, and troubleshooting issues.

For detailed reference on specific commands, see:

- Makefile commands: [7.1](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/7.1-makefile-command-reference)
- Control commands and their effects: [7.2](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/7.2-control-commands)
- Monitoring tools and data interpretation: [7.3](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/7.3-monitoring-and-data-streams)
- Infrastructure service management: [7.4](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/7.4-infrastructure-services)

For system architecture and component details, see [System Architecture](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/3-system-architecture). For configuration options, see [Configuration Reference](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6-configuration-reference).

## Operational Architecture Overview

The Adeline system follows a three-tier operational model: **infrastructure services** (MQTT broker, RTSP proxy), **pipeline execution** (YOLO inference), and **control interfaces** (CLI, MQTT commands). All operations are orchestrated through the Makefile, which provides a unified command interface.

**Sources:** [Makefile1-240](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L1-L240) [adeline/control/cli.py1-88](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L1-L88) [README.md1-215](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L1-L215)

## System States and Transitions

The InferencePipeline operates as a state machine. Understanding these states is critical for effective operations.

**Sources:** [README.md78-102](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L78-L102) [Makefile74-110](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L74-L110)

## Operational Workflow

### Standard Startup Sequence

The recommended startup sequence ensures all dependencies are available before the pipeline starts:

1. **Install dependencies** (first time only):
    
    ```
    make install
    ```
    
2. **Start infrastructure services**:
    
    ```
    make services-up
    ```
    
    This starts the MQTT broker using [docker/adeline/docker-compose.mqtt.yml](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/docker/adeline/docker-compose.mqtt.yml)
    
3. **Verify configuration**:
    
    - Check that [config/adeline/config.yaml](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/config/adeline/config.yaml) exists and is valid
    - Check that [.env](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/.env) contains required credentials (API keys, MQTT credentials)
4. **Start the pipeline**:
    
    ```
    make run
    ```
    
    This executes `python -m adeline`, which starts [adeline/__main__.py1](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/__main__.py#L1-LNaN)
    
5. **Verify operation**:
    
    ```
    make status
    ```
    

**Sources:** [README.md54-89](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L54-L89) [Makefile52-77](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L52-L77)

### Pipeline Control During Operation

Once running, the pipeline accepts commands via MQTT. The Makefile provides convenient shortcuts:

|Command|Effect|MQTT Command|Implementation|
|---|---|---|---|
|`make pause`|Stop inference temporarily|`{"command": "pause"}`|[adeline/control/cli.py59](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L59-L59)|
|`make resume`|Resume inference|`{"command": "resume"}`|[adeline/control/cli.py59](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L59-L59)|
|`make stop`|Graceful shutdown|`{"command": "stop"}`|[adeline/control/cli.py59](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L59-L59)|
|`make status`|Query current state|`{"command": "status"}`|[adeline/control/cli.py59](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L59-L59)|
|`make metrics`|Request performance metrics|`{"command": "metrics"}`|[adeline/control/cli.py59](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L59-L59)|
|`make toggle-crop`|Enable/disable adaptive ROI|`{"command": "toggle_crop"}`|[adeline/control/cli.py59](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L59-L59)|
|`make stabilization-stats`|Get stabilization statistics|`{"command": "stabilization_stats"}`|[adeline/control/cli.py59](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L59-L59)|

All commands are sent with **QoS 1** to ensure reliable delivery.

**Sources:** [Makefile84-110](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L84-L110) [adeline/control/cli.py21-51](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L21-L51)

## Command Execution Flow

This diagram shows how operator commands flow through the system, mapping high-level Makefile commands to specific code execution paths:

**Sources:** [Makefile88-110](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L88-L110) [adeline/control/cli.py1-88](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/cli.py#L1-L88)

## Monitoring Operations

The system provides two monitoring interfaces for observing runtime behavior:

### Data Stream Monitoring

Monitor real-time detection output:

```
make monitor-data
```

This runs [adeline/data/monitors/__main__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/monitors/__main__.py) and subscribes to `inference/data/detections` (QoS 0). Output includes:

- Detection timestamps
- Object classes and confidence scores
- Bounding box coordinates
- Frame metadata

### Status Monitoring

Monitor pipeline state changes and health:

```
make monitor-status
```

Subscribes to `inference/control/status` (QoS 1). Shows:

- State transitions (RUNNING → PAUSED)
- Command acknowledgments
- Error conditions
- Performance metrics responses

**Sources:** [Makefile115-125](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L115-L125) [README.md91-102](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L91-L102)

## Infrastructure Management

### Service Lifecycle

The MQTT broker is managed via Docker Compose:

|Command|Purpose|Implementation|
|---|---|---|
|`make services-up`|Start MQTT broker|[Makefile148](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L148-L148) → docker-compose up|
|`make services-down`|Stop MQTT broker|[Makefile149](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L149-L149) → docker-compose down|
|`make services-status`|Check service health|[Makefile151](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L151-L151) → docker-compose ps|
|`make services-logs`|View broker logs|[Makefile150](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L150-L150) → docker-compose logs|

The broker configuration is in [docker/adeline/docker-compose.mqtt.yml](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/docker/adeline/docker-compose.mqtt.yml) and [docker/adeline/mosquitto.conf](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/docker/adeline/mosquitto.conf)

**Sources:** [Makefile130-151](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L130-L151) [README.md183-199](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L183-L199)

### Service Dependencies

**Sources:** [README.md197-199](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L197-L199) [docker/adeline/docker-compose.mqtt.yml1](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/docker/adeline/docker-compose.mqtt.yml#L1-LNaN)

## Troubleshooting Guide

### Common Issues

#### Pipeline Fails to Start

**Symptom:** `make run` exits immediately or shows connection errors.

**Diagnosis:**

1. Check if MQTT broker is running:
    
    ```
    make services-status
    ```
    
2. Verify broker accessibility:
    
    ```
    mosquitto_sub -h localhost -p 1883 -t "test" -v
    ```
    
3. Check configuration files exist:
    
    - [config/adeline/config.yaml](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/config/adeline/config.yaml)
    - [.env](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/.env)

**Resolution:**

- Start services: `make services-up`
- Verify MQTT credentials in [.env](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/.env)
- Check logs: `make services-logs`

#### Commands Not Responding

**Symptom:** `make pause` or `make stop` have no effect.

**Diagnosis:**

1. Verify pipeline is running:
    
    ```
    ps aux | grep "python -m adeline"
    ```
    
2. Check MQTT connectivity:
    
    ```
    mosquitto_sub -h localhost -p 1883 -t "inference/control/status" -v
    ```
    
3. Test command publishing:
    
    ```
    mosquitto_pub -h localhost -p 1883 -t "inference/control/commands" -m '{"command":"status"}' -q 1
    ```
    

**Resolution:**

- Restart pipeline: Stop process, then `make run`
- Check MQTT broker logs for connection issues
- Verify QoS settings (commands require QoS 1)

#### High Latency or Dropped Detections

**Symptom:** Slow detection publishing or gaps in `make monitor-data` output.

**Diagnosis:**

1. Check system resources:
    
    ```
    top  # Check CPU/memory usage
    ```
    
2. Request metrics:
    
    ```
    make metrics
    ```
    
3. Monitor data plane:
    
    ```
    make monitor-data --verbose
    ```
    

**Resolution:**

- Reduce inference FPS in [config/adeline/config.yaml](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/config/adeline/config.yaml)
- Enable adaptive ROI to reduce inference area
- Consider using local ONNX models instead of Roboflow API
- Check network latency to MQTT broker

**Sources:** [README.md1-215](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L1-L215) [Makefile1-240](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L1-L240)

## Graceful Shutdown

The system supports graceful shutdown through multiple mechanisms:

### Signal-Based Shutdown

When the pipeline is running in foreground:

1. Press `Ctrl+C` (sends SIGINT)
2. The `InferencePipelineController` catches the signal
3. Cleanup executes:
    - Close MQTT connections
    - Release video sources
    - Flush pending messages

If the process doesn't stop after 5 seconds, press `Ctrl+C` again or send SIGTERM.

### Command-Based Shutdown

For background processes or remote control:

```
make stop
```

This sends an MQTT stop command (QoS 1), triggering the same cleanup sequence.

**Sources:** [README.md76-89](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L76-L89) [Makefile84-86](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L84-L86)

## Quick Reference Card

### Essential Commands

```
# Setup (first time)
make install
make services-up

# Run pipeline
make run

# Control pipeline
make pause                    # Pause inference
make resume                   # Resume inference
make stop                     # Stop pipeline
make status                   # Query state

# Monitor
make monitor-data            # Watch detections
make monitor-status          # Watch state changes
make metrics                 # Get performance stats

# Advanced
make toggle-crop             # Toggle adaptive ROI
make stabilization-stats     # Query stabilizer state

# Infrastructure
make services-up             # Start MQTT broker
make services-down           # Stop MQTT broker
make services-status         # Check services
make services-logs           # View logs

# Cleanup
make clean                   # Remove temp files
```

**Sources:** [Makefile1-240](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/Makefile#L1-L240) [README.md54-102](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L54-L102)

## Operational Best Practices

1. **Always start infrastructure first**: Run `make services-up` before `make run`
    
2. **Use status checks**: After any command, run `make status` to verify the change took effect
    
3. **Monitor during changes**: Keep `make monitor-status` running when testing configuration changes
    
4. **Graceful shutdown**: Prefer `make stop` over killing the process to ensure clean disconnection
    
5. **Check logs on failure**: Use `make services-logs` to diagnose MQTT connectivity issues
    
6. **Test with pause/resume**: Before stopping, test that pause/resume work to verify control plane health
    
7. **Keep services running**: Leave `make services-up` running across pipeline restarts to avoid reconnection delays
    

**Sources:** [README.md1-215](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/README.md#L1-L215)