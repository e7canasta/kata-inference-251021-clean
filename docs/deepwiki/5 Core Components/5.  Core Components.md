# Core Components

Relevant source files

- [adeline/CLAUDE.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md)
- [adeline/__init__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/__init__.py)

## Purpose and Scope

This section provides comprehensive documentation of the major components that comprise the Adeline inference system. Each component has specific responsibilities and well-defined interfaces that enable the system's modular architecture.

The core components documented here are:

- **Pipeline Controller**: Orchestration and lifecycle management
- **Inference Pipeline**: YOLO-based object detection processing
- **Control Plane**: MQTT command handling (QoS 1)
- **Data Plane**: MQTT data publishing (QoS 0)
- **ROI Strategies**: Region of interest processing
- **Detection Stabilization**: Temporal filtering for stable detections

For detailed documentation of individual components, see the respective subsections: [Pipeline Controller](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.1-pipeline-controller), [Inference Pipeline](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.2-inference-pipeline), [Control Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.3-control-plane), [Data Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.4-data-plane), [ROI Strategies](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.5-roi-strategies), and [Detection Stabilization](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.6-detection-stabilization).

For understanding how these components fit into the overall architecture, see [System Architecture](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/3-system-architecture). For configuration options that control component behavior, see [Configuration Reference](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6-configuration-reference).

---

## Component Architecture Overview

The Adeline system is structured around six primary components that work together to provide real-time object detection with remote control capabilities. The following diagram illustrates the component hierarchy and their relationships:

**Sources:** [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py) [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py) [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/inference/roi/__init__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/roi/__init__.py) [adeline/inference/stabilization/core.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/stabilization/core.py) [adeline/CLAUDE.md26-43](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L26-L43)

---

## Component Responsibilities

Each component has a well-defined set of responsibilities within the system:

|Component|Primary Responsibility|Key Methods/Classes|Configuration Source|
|---|---|---|---|
|**InferencePipelineController**|Orchestrates all components, manages lifecycle, handles signals|`main()`, `run()`, `setup_signal_handlers()`|`PipelineConfig`|
|**MQTTControlPlane**|Receives and processes commands via MQTT (QoS 1)|`connect()`, `on_stop()`, `on_pause()`, `on_resume()`|`config.mqtt`|
|**MQTTDataPlane**|Publishes detection results and metrics via MQTT (QoS 0)|`connect()`, `publish_detections()`, `publish_metrics()`|`config.mqtt`|
|**InferencePipeline**|Performs YOLO object detection on video frames|`init()`, `start()`, `terminate()`, `on_prediction`|`config.pipeline`|
|**ROI Strategies**|Determines region of interest for inference|`create_roi_strategy()`, `AdaptiveROIStrategy`, `FixedROIStrategy`|`config.roi_strategy`|
|**Stabilization Strategies**|Filters detections to reduce flickering|`create_stabilization_strategy()`, `TemporalHysteresisStabilization`|`config.stabilization`|

**Sources:** [adeline/CLAUDE.md22-43](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L22-L43) [adeline/__init__.py1-45](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/__init__.py#L1-L45)

---

## Component Communication Flow

The following sequence diagram shows how components interact during typical operation, from initialization through detection processing:

**Sources:** [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py) [adeline/CLAUDE.md39-43](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L39-L43)

---

## Component Initialization Order

The initialization of components follows a critical order to ensure proper system startup. The following diagram illustrates this dependency chain:

The initialization sequence enforces these critical requirements:

1. **Configuration Loading**: `PipelineConfig` loads settings from `config.yaml` and `.env`
2. **Model Disabling**: `disable_models_from_config()` MUST execute before importing inference modules [adeline/config.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py)
3. **Controller Creation**: `InferencePipelineController` instantiated with config
4. **MQTT Planes**: Control and Data planes created with separate client IDs
5. **Strategy Factories**: ROI and stabilization strategies created via factory functions
6. **Pipeline Initialization**: `InferencePipeline` initialized with strategies and sinks

**Sources:** [adeline/config.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py) [adeline/CLAUDE.md44-54](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L44-L54) [adeline/__main__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/__main__.py)

---

## InferencePipelineController

The `InferencePipelineController` is the central orchestrator that manages all other components. It resides in [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py) and is responsible for:

- Creating and initializing all system components
- Setting up signal handlers for graceful shutdown (SIGINT, SIGTERM)
- Starting and stopping the inference pipeline
- Coordinating between Control Plane and Data Plane
- Managing the multi-sink pattern for output distribution

**Key Methods:**

- `main()`: Entry point that creates controller and starts execution
- `run()`: Main execution loop that starts pipeline and handles shutdown
- `setup_signal_handlers()`: Registers handlers for SIGINT/SIGTERM

For detailed documentation, see [Pipeline Controller](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.1-pipeline-controller).

**Sources:** [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py) [adeline/CLAUDE.md39-43](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L39-L43)

---

## MQTTControlPlane

The `MQTTControlPlane` component handles incoming commands via MQTT with QoS 1 (reliable delivery). It implements the control plane of the control/data plane separation pattern. Located in [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py) it provides:

- Command reception on topic `inference/control/commands`
- Status publishing on topic `inference/control/status`
- Callback-based command processing (pause, resume, stop, status, toggle_crop, stabilization_stats)
- Reliable message delivery guarantees via QoS 1

**Key Methods:**

- `connect()`: Establishes MQTT connection and subscribes to command topic
- `on_stop()`, `on_pause()`, `on_resume()`: Lifecycle callbacks
- `on_metrics()`, `on_toggle_crop()`, `on_stabilization_stats()`: Query callbacks
- `publish_status()`: Publishes pipeline state changes

For detailed documentation, see [Control Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.3-control-plane).

**Sources:** [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py) [adeline/CLAUDE.md26-32](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L26-L32)

---

## MQTTDataPlane

The `MQTTDataPlane` component handles outgoing detection data and metrics via MQTT with QoS 0 (best-effort delivery). Located in [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) it provides:

- Detection result publishing on topic `inference/data/detections`
- Metrics publishing on topic `inference/data/metrics`
- Watchdog monitoring for pipeline health
- High-throughput data streaming with minimal latency

**Key Methods:**

- `connect()`: Establishes MQTT connection for data publishing
- `publish_detections()`: Sends detection results to MQTT
- `publish_metrics()`: Publishes performance metrics
- `start_watchdog()`: Initializes watchdog timer

For detailed documentation, see [Data Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.4-data-plane).

**Sources:** [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/CLAUDE.md33-38](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L33-L38)

---

## InferencePipeline

The `InferencePipeline` is the core detection component from the `inference` library. It performs YOLO-based object detection on video frames. Key characteristics:

- Processes RTSP video streams
- Supports both local ONNX models and Roboflow API models
- Integrates with ROI strategies for selective processing
- Integrates with stabilization strategies for filtered output
- Uses multi-sink pattern to distribute results

**Configuration Points:**

- Model selection via `config.pipeline.model_id`
- Video source via `config.pipeline.video_reference`
- Frame rate via `config.pipeline.max_fps`
- Confidence threshold via `config.pipeline.confidence`

For detailed documentation, see [Inference Pipeline](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.2-inference-pipeline).

**Sources:** [adeline/inference/models.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/models.py) [adeline/CLAUDE.md71-74](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L71-L74)

---

## ROI Strategy System

The ROI (Region of Interest) strategy system enables selective processing of video frames. Located in [adeline/inference/roi/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/roi/) it uses a factory pattern to create different strategies:

|Strategy|Class|Purpose|Configuration|
|---|---|---|---|
|**None**|`NoneROIStrategy`|Process entire frame|`roi_strategy.mode: "none"`|
|**Adaptive**|`AdaptiveROIStrategy`|Dynamic crop based on detections|`roi_strategy.mode: "adaptive"`|
|**Fixed**|`FixedROIStrategy`|Static region coordinates|`roi_strategy.mode: "fixed"`|

**Factory Function:** `create_roi_strategy(config)` in [adeline/inference/roi/__init__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/roi/__init__.py)

**Runtime Control:** The `toggle_crop` MQTT command enables/disables ROI processing dynamically.

For detailed documentation, see [ROI Strategies](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.5-roi-strategies).

**Sources:** [adeline/inference/roi/__init__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/roi/__init__.py) [adeline/CLAUDE.md57-63](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L57-L63)

---

## Stabilization Strategy System

The stabilization strategy system reduces detection flickering through temporal filtering. Located in [adeline/inference/stabilization/](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/stabilization/) it uses a factory pattern to create different strategies:

|Strategy|Class|Purpose|Key Parameters|
|---|---|---|---|
|**None**|`NoneStabilization`|No filtering|-|
|**Temporal**|`TemporalHysteresisStabilization`|Requires N consecutive frames|`high_threshold`, `low_threshold`, `n_frames`|

**Factory Function:** `create_stabilization_strategy(config)` in [adeline/inference/stabilization/core.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/stabilization/core.py)

**How It Works:**

- High threshold (e.g., 0.5): Confidence needed for first appearance
- Low threshold (e.g., 0.3): Confidence needed to persist once appeared
- N frames: Number of consecutive detections required

**Runtime Query:** The `stabilization_stats` MQTT command returns current stabilization statistics.

For detailed documentation, see [Detection Stabilization](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.6-detection-stabilization).

**Sources:** [adeline/inference/stabilization/core.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/inference/stabilization/core.py) [adeline/CLAUDE.md64-70](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L64-L70)

---

## Multi-Sink Pattern Implementation

Components use the multi-sink pattern from the `inference` library to distribute detection results to multiple destinations simultaneously. This pattern is configured in the Pipeline Controller:

The multi-sink pattern enables:

- **Parallel Output**: Detections sent to MQTT, visualization, and ROI updates simultaneously
- **Loose Coupling**: Adding/removing sinks doesn't require pipeline changes
- **Performance**: Each sink processes independently without blocking others

**Sources:** [adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py) [adeline/CLAUDE.md113-121](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L113-L121)

---

## Component Lifecycle States

The following table summarizes the lifecycle states of each component:

|Component|States|Transitions|Controlled By|
|---|---|---|---|
|**InferencePipeline**|`stopped`, `running`, `paused`, `terminated`|MQTT commands or signals|Control Plane callbacks|
|**MQTTControlPlane**|`disconnected`, `connected`|Automatic reconnection|MQTT client|
|**MQTTDataPlane**|`disconnected`, `connected`|Automatic reconnection|MQTT client|
|**ROI Strategy**|`enabled`, `disabled` (adaptive/fixed only)|`toggle_crop` command|Control Plane|
|**Stabilization**|Always active (no state)|Configured at startup|Configuration only|

**Shutdown Sequence:**

1. Signal handler catches SIGINT/SIGTERM
2. Controller calls `pipeline.terminate()`
3. Pipeline stops processing frames
4. MQTT planes disconnect gracefully
5. Resources released

**Sources:** [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py) [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)

---

## Configuration Integration

Each component reads its configuration from the `PipelineConfig` object, which consolidates settings from multiple sources:

**Configuration Hierarchy:**

1. `.env` file: MQTT credentials, API keys (highest precedence for secrets)
2. `config.yaml`: All pipeline settings, strategies, thresholds
3. Defaults: Hardcoded fallbacks in `PipelineConfig` class

For complete configuration reference, see [Configuration Reference](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/6-configuration-reference).

**Sources:** [adeline/config.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/config.py) [adeline/CLAUDE.md44-54](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L44-L54)