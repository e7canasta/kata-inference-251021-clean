# Pipeline Controller

Relevant source files

- [adeline/CLAUDE.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md)
- [adeline/app/__init__.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/__init__.py)
- [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py)

## Purpose and Scope

The Pipeline Controller (`InferencePipelineController`) is the central orchestrator of the Adeline inference system. It coordinates the Control Plane, Data Plane, and Inference Pipeline components, manages their lifecycle, and handles graceful shutdown. This document covers the controller's architecture, initialization sequence, command handling, and shutdown procedures.

For information about the individual planes it orchestrates, see [Control Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.3-control-plane) and [Data Plane](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.4-data-plane). For the inference logic itself, see [Inference Pipeline](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/5.2-inference-pipeline). For overall system architecture, see [Component Overview](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/3.3-component-overview).

**Sources:** [adeline/app/controller.py1-562](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L1-L562)

---

## Overview and Responsibilities

The `InferencePipelineController` class serves as the main application orchestrator, implementing the following core responsibilities:

|Responsibility|Description|
|---|---|
|**Component Coordination**|Initializes and manages Control Plane, Data Plane, and Inference Pipeline|
|**Lifecycle Management**|Handles setup, startup, running state, and graceful shutdown|
|**Signal Handling**|Registers SIGINT/SIGTERM handlers for graceful termination|
|**Command Dispatching**|Routes MQTT commands to appropriate handlers|
|**Resource Cleanup**|Ensures proper disconnection and resource release on shutdown|
|**Configuration Integration**|Applies `PipelineConfig` settings to all components|

The controller is instantiated with a `PipelineConfig` object and exposes a single `run()` method that blocks until shutdown is triggered.

**Sources:** [adeline/app/controller.py54-66](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L54-L66) [adeline/app/controller.py533-557](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L533-L557)

---

## Architecture and Component Coordination

### Component Relationship Diagram

**Sources:** [adeline/app/controller.py54-66](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L54-L66) [adeline/app/controller.py68-319](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L68-L319)

### Controller State Fields

The controller maintains the following instance variables:

|Field|Type|Purpose|
|---|---|---|
|`config`|`PipelineConfig`|Configuration object passed at initialization|
|`pipeline`|`InferencePipeline`|Main inference pipeline instance|
|`control_plane`|`MQTTControlPlane`|Handles incoming MQTT commands|
|`data_plane`|`MQTTDataPlane`|Publishes inference results and metrics|
|`watchdog`|`BasePipelineWatchDog`|Collects and reports pipeline metrics|
|`shutdown_event`|`threading.Event`|Coordination point for graceful shutdown|
|`is_running`|`bool`|Tracks whether pipeline is actively running|
|`roi_state`|`AdaptiveROI` / `FixedROI`|ROI strategy state (if enabled)|
|`stabilizer`|`TemporalHysteresisStrategy`|Detection stabilizer (if enabled)|
|`inference_handler`|`AdaptiveInferenceHandler` / `FixedROIInferenceHandler`|Custom inference wrapper (if ROI enabled)|

**Sources:** [adeline/app/controller.py59-66](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L59-L66)

---

## Initialization Sequence

The initialization process follows a strict order to prevent dependency issues and ensure proper component configuration.

### Critical Initialization Order

**Sources:** [adeline/app/controller.py68-319](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L68-L319) [adeline/app/controller.py436-474](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L436-L474) [adeline/app/controller.py533-557](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L533-L557)

### Setup Method Breakdown

The `setup()` method [adeline/app/controller.py68-319](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L68-L319) follows this detailed sequence:

1. **Data Plane Configuration** [adeline/app/controller.py72-92](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L72-L92)
    
    - Create `MQTTDataPlane` with broker credentials
    - Connect with 10-second timeout
    - Attach `BasePipelineWatchDog` for metrics collection
2. **Sink Creation** [adeline/app/controller.py92-125](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L92-L125)
    
    - Create base MQTT sink via `create_mqtt_sink()`
    - Optionally wrap with stabilization sink if `STABILIZATION_MODE != 'none'`
    - Uses factory pattern: `create_stabilization_strategy()` and `create_stabilization_sink()`
3. **Pipeline Creation** [adeline/app/controller.py127-276](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L127-L276)
    
    - **Path A: Custom Logic (ROI enabled)** [adeline/app/controller.py131-245](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L131-L245)
        - Validate and create ROI strategy using `validate_and_create_roi_strategy()`
        - Load model via `get_model_from_config()`
        - Create appropriate handler: `AdaptiveInferenceHandler` or `FixedROIInferenceHandler`
        - Configure sinks: MQTT + ROI update (adaptive only) + visualization (optional)
        - Initialize with `InferencePipeline.init_with_custom_logic()`
    - **Path B: Standard Logic (no ROI)** [adeline/app/controller.py248-276](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L248-L276)
        - Configure sinks: MQTT + visualization (optional)
        - Initialize with `InferencePipeline.init()`
4. **Control Plane Configuration** [adeline/app/controller.py278-305](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L278-L305)
    
    - Create `MQTTControlPlane` with broker credentials
    - Register command callbacks: `on_stop`, `on_pause`, `on_resume`, `on_metrics`
    - Conditionally register `on_toggle_crop` (adaptive ROI only)
    - Conditionally register `on_stabilization_stats` (if stabilization enabled)
    - Connect with 10-second timeout
5. **Auto-Start Pipeline** [adeline/app/controller.py307-319](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L307-L319)
    
    - Set `is_running = True` before calling `start()` (prevents race condition)
    - Call `pipeline.start()` to begin automatic inference
    - Log success or revert `is_running` on failure

**Sources:** [adeline/app/controller.py68-319](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L68-L319)

---

## Command Handling

The controller registers callback methods with the Control Plane to handle incoming MQTT commands. Each callback implements a specific control operation.

### Command Flow Diagram

**Sources:** [adeline/app/controller.py328-434](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L328-L434)

### Command Handler Methods

#### `_handle_stop()` [adeline/app/controller.py328-341](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L328-L341)

Handles the `stop` command, which terminates the pipeline and exits the program:

- Calls `pipeline.terminate()` if pipeline is running
- Sets `is_running = False`
- Sets `shutdown_event` to trigger program exit
- Cleanup happens in `cleanup()` method

#### `_handle_pause()` [adeline/app/controller.py343-353](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L343-L353)

Handles the `pause` command, which temporarily stops frame processing:

- Calls `pipeline.pause_stream()` if pipeline is running
- Pipeline can be resumed with `resume` command
- Does not disconnect from MQTT or release resources

#### `_handle_resume()` [adeline/app/controller.py355-365](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L355-L365)

Handles the `resume` command, which continues processing after pause:

- Calls `pipeline.resume_stream()` if pipeline is running
- Resumes frame capture and inference
- Logs warning if pipeline is not running

#### `_handle_metrics()` [adeline/app/controller.py367-373](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L367-L373)

Handles the `metrics` command, which publishes current pipeline metrics:

- Calls `data_plane.publish_metrics()`
- Metrics are collected by `BasePipelineWatchDog`
- Published to `inference/data/metrics` topic

#### `_handle_toggle_crop()` [adeline/app/controller.py375-397](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L375-L397)

Handles the `toggle_crop` command, which enables/disables adaptive ROI cropping:

- Only available when `ROI_MODE == 'adaptive'`
- Toggles `inference_handler.enabled` flag
- Optionally resets ROI state when disabling
- Logs warning if not in adaptive mode

#### `_handle_stabilization_stats()` [adeline/app/controller.py399-434](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L399-L434)

Handles the `stabilization_stats` command, which logs detection stabilization statistics:

- Only available when `STABILIZATION_MODE != 'none'`
- Calls `stabilizer.get_stats(source_id=0)`
- Logs comprehensive statistics: total detected, confirmed, ignored, removed, active tracks, confirm ratio
- Includes breakdown by detection class

**Sources:** [adeline/app/controller.py328-434](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L328-L434)

---

## Signal Handling and Graceful Shutdown

The controller implements robust signal handling to ensure graceful shutdown when the process receives termination signals.

### Signal Handler Registration

Signal handlers are registered in the `run()` method [adeline/app/controller.py461-463](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L461-L463):

```
signal.signal(signal.SIGINT, self._signal_handler)
signal.signal(signal.SIGTERM, self._signal_handler)
```

### Signal Handler Implementation

The `_signal_handler()` method [adeline/app/controller.py476-487](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L476-L487) handles both SIGINT (Ctrl+C) and SIGTERM:

1. Logs termination signal receipt
2. Sets `shutdown_event` to trigger main loop exit
3. Immediately calls `pipeline.terminate()` if running
4. Sets `is_running = False`

### Shutdown Sequence Diagram

**Sources:** [adeline/app/controller.py476-527](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L476-L527)

### Cleanup Method Details

The `cleanup()` method [adeline/app/controller.py489-527](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L489-L527) performs the following operations:

1. **Pipeline Termination** [adeline/app/controller.py494-508](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L494-L508)
    
    - Only terminate if `is_running` is still `True` (prevents double termination)
    - Call `pipeline.terminate()`
    - Wait for threads to finish with `pipeline.join(timeout=3.0)`
    - Log warning if threads don't finish within timeout
2. **Control Plane Disconnection** [adeline/app/controller.py510-512](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L510-L512)
    
    - Call `control_plane.disconnect()`
    - Closes MQTT connection and stops loop thread
3. **Data Plane Disconnection** [adeline/app/controller.py514-518](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L514-L518)
    
    - Call `data_plane.get_stats()` and log final statistics
    - Call `data_plane.disconnect()`
    - Closes MQTT connection and stops loop thread
4. **Forced Exit** [adeline/app/controller.py522-527](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L522-L527)
    
    - Use `os._exit(0)` instead of `sys.exit()` to immediately kill all threads
    - Bypasses Python's cleanup to avoid hanging on non-daemon threads
    - Ensures program exits even if pipeline threads don't terminate cleanly

**Sources:** [adeline/app/controller.py489-527](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L489-L527)

---

## Configuration Integration

The controller applies configuration from `PipelineConfig` throughout the initialization process.

### Configuration Categories

|Category|Configuration Fields|Usage Location|
|---|---|---|
|**MQTT Broker**|`MQTT_BROKER`, `MQTT_PORT`, `MQTT_USERNAME`, `MQTT_PASSWORD`|Control Plane, Data Plane connection|
|**MQTT Topics**|`CONTROL_COMMAND_TOPIC`, `CONTROL_STATUS_TOPIC`, `DATA_TOPIC`, `METRICS_TOPIC`|Control Plane, Data Plane topic subscriptions|
|**QoS Settings**|`DATA_QOS`|Data Plane message publishing|
|**Pipeline**|`RTSP_URL`, `MAX_FPS`|InferencePipeline initialization|
|**Model**|`MODEL_ID`, `API_KEY`, `USE_LOCAL_MODEL`, `LOCAL_MODEL_PATH`, `MODEL_CONFIDENCE`, `MODEL_IOU_THRESHOLD`, `MODEL_IMGSZ`|Model loading and inference configuration|
|**ROI Strategy**|`ROI_MODE`, `CROP_MARGIN`, `CROP_SMOOTHING`, `CROP_MIN_ROI_MULTIPLE`, `CROP_MAX_ROI_MULTIPLE`, `FIXED_X_MIN`, `FIXED_Y_MIN`, `FIXED_X_MAX`, `FIXED_Y_MAX`|ROI strategy creation|
|**Stabilization**|`STABILIZATION_MODE`, `STABILIZATION_MIN_FRAMES`, `STABILIZATION_MAX_GAP`, `STABILIZATION_APPEAR_CONF`, `STABILIZATION_PERSIST_CONF`|Stabilization strategy creation|
|**Visualization**|`ENABLE_VISUALIZATION`, `DISPLAY_STATISTICS`, `CROP_SHOW_STATISTICS`|Visualization sink creation|
|**Logging**|`LOG_LEVEL`, `LOG_FORMAT`, `PAHO_LOG_LEVEL`|Logging configuration in `main()`|

**Sources:** [adeline/app/controller.py59-60](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L59-L60) [adeline/app/controller.py74-82](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L74-L82) [adeline/app/controller.py131-276](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L131-L276) [adeline/app/controller.py533-557](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L533-L557)

### Configuration-Driven Behavior Selection

The controller uses configuration values to determine which code paths to execute:

**Sources:** [adeline/app/controller.py94-125](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L94-L125) [adeline/app/controller.py131-276](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L131-L276)

---

## Entry Point and Main Function

The controller is executed via the `main()` function, which serves as the entry point for `python -m adeline`.

### Main Function Flow [adeline/app/controller.py533-557](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L533-L557)

1. **Load Configuration**
    
    - Instantiate `PipelineConfig()`
    - Loads from `.env` and `config.yaml`
2. **Configure Logging**
    
    - Set global logging level from `config.LOG_LEVEL`
    - Set log format from `config.LOG_FORMAT`
    - Reduce `paho-mqtt` verbosity using `config.PAHO_LOG_LEVEL`
3. **Create and Run Controller**
    
    - Instantiate `InferencePipelineController(config)`
    - Call `controller.run()`
    - Handle fatal exceptions with logging and `sys.exit(1)`

### Module Entry Points

The controller can be invoked via multiple entry points:

|Entry Point|Module|Target Function|
|---|---|---|
|`python -m adeline`|`adeline/__main__.py`|`adeline.app.main()`|
|Direct import|`from adeline.app import main`|`main()`|

**Sources:** [adeline/app/controller.py533-557](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L533-L557) [adeline/app/__init__.py1-6](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/__init__.py#L1-L6)

---

## Key Design Patterns

### Dependency Injection

The controller receives `PipelineConfig` at initialization [adeline/app/controller.py59-60](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L59-L60) enabling:

- Testability (mock config in tests)
- Configuration validation before component creation
- Clear dependency flow from config to components

### Callback Registration

The controller registers callback methods with Control Plane [adeline/app/controller.py290-301](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L290-L301) implementing:

- Loose coupling between MQTT handling and command execution
- Conditional callback registration based on configuration
- Clear separation of concerns (Control Plane handles MQTT, controller handles logic)

### Factory Pattern Integration

The controller uses factory functions for strategy creation:

- `validate_and_create_roi_strategy()` [adeline/app/controller.py165-168](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L165-L168)
- `create_stabilization_strategy()` [adeline/app/controller.py114](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L114-L114)
- `create_mqtt_sink()` [adeline/app/controller.py92](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L92-L92)
- `create_visualization_sink()` [adeline/app/controller.py226-232](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L226-L232)

### Multi-Sink Composition

The controller composes multiple sinks using `multi_sink` [adeline/app/controller.py234](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L234-L234):

- Enables parallel output to MQTT, visualization, and ROI updates
- Uses `functools.partial` for lazy sink creation
- Maintains separation between sink logic and pipeline logic

**Sources:** [adeline/app/controller.py92](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L92-L92) [adeline/app/controller.py114](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L114-L114) [adeline/app/controller.py165-168](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L165-L168) [adeline/app/controller.py214-234](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L214-L234)

---

## Error Handling and Recovery

### Connection Failures

Both Control Plane and Data Plane connections include timeout handling [adeline/app/controller.py84-86](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L84-L86) [adeline/app/controller.py303-305](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L303-L305):

- Return `False` from `setup()` if connection fails
- Prevents pipeline from starting without MQTT connectivity
- Logs error message for debugging

### Pipeline Start Failures

The auto-start sequence includes exception handling [adeline/app/controller.py309-316](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L309-L316):

- Wraps `pipeline.start()` in try/except
- Reverts `is_running` flag if start fails
- Returns `False` from `setup()` to prevent entering main loop

### Signal Handler Race Conditions

The signal handler sets `is_running = False` before cleanup [adeline/app/controller.py481-486](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L481-L486):

- Prevents double termination in `cleanup()` method
- Ensures cleanup only terminates pipeline if signal handler hasn't already
- Check `if self.pipeline and self.is_running:` in cleanup [adeline/app/controller.py494](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L494-L494)

### Thread Join Timeout

The cleanup method includes timeout for thread termination [adeline/app/controller.py503-506](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L503-L506):

- Waits up to 3 seconds for pipeline threads to finish
- Logs warning but continues cleanup if timeout occurs
- Forces exit with `os._exit(0)` regardless of thread state [adeline/app/controller.py527](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L527-L527)

**Sources:** [adeline/app/controller.py84-86](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L84-L86) [adeline/app/controller.py303-316](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L303-L316) [adeline/app/controller.py476-527](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py#L476-L527)