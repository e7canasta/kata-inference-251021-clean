# Control and Data Plane Separation

Relevant source files

- [adeline/CLAUDE.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md)
- [adeline/DESIGN.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md)
- [adeline/README.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/README.md)

## Purpose and Scope

This page documents the architectural pattern of separating control and data communication into two independent MQTT planes with different Quality of Service (QoS) guarantees. The control plane handles lifecycle commands and status updates with reliable delivery (QoS 1), while the data plane handles high-volume inference results and metrics with best-effort delivery (QoS 0).

For information about the broader MQTT communication architecture and topic structure, see [MQTT Communication Architecture](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/3.2-mqtt-communication-architecture). For details on individual components, see [Component Overview](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/3.3-component-overview).

---

## Architectural Rationale

The separation of control and data planes addresses a fundamental tension in distributed systems: the need for both reliability and performance.

### Problem Statement

A single MQTT communication channel with uniform QoS presents two competing requirements:

1. **Control commands** (pause, resume, stop) must be reliably delivered - missing a stop command could leave the system in an inconsistent state
2. **Inference data** (detections, metrics) arrives at high frequency (30+ FPS) where occasional message loss is acceptable but latency is not

Using QoS 1 for all traffic guarantees delivery but introduces latency and broker overhead. Using QoS 0 for all traffic maximizes throughput but risks losing critical commands.

### Solution: Dual Plane Architecture

The system implements two independent MQTT clients, each optimized for its domain:

|Aspect|Control Plane|Data Plane|
|---|---|---|
|**Class**|`MQTTControlPlane`|`MQTTDataPlane`|
|**QoS Level**|1 (at-least-once)|0 (at-most-once)|
|**Client ID**|`inference_control`|`inference_data`|
|**Message Volume**|Low frequency|High frequency|
|**Criticality**|High (commands/status)|Medium (data/metrics)|
|**Latency Tolerance**|Low|Very low|

**Sources:** [adeline/CLAUDE.md23-37](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L23-L37) [adeline/DESIGN.md9-22](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L9-L22)

---

## Control Plane Architecture

### Responsibilities

The `MQTTControlPlane` class manages the reliable command and control channel for the inference pipeline.

**Diagram: Control Plane Command Flow**

### Command Protocol

Commands are JSON messages with a simple structure:

```
{
  "command": "pause|resume|stop|status|metrics|toggle_crop|stabilization_stats"
}
```

Each command triggers a registered callback in the `InferencePipelineController`, which executes the corresponding action and optionally publishes status updates.

**Sources:** [adeline/CLAUDE.md27-31](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L27-L31) [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)

### Key Implementation Details

The `MQTTControlPlane` class is initialized with:

- **Broker connection parameters** (host, port, credentials)
- **Callback registry** for each command type
- **QoS 1 subscription** to `inference/control/commands`
- **QoS 1 publishing** to `inference/control/status`

The control plane maintains a persistent connection to the MQTT broker and automatically reconnects on network failures, ensuring commands are not lost.

**Sources:** [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)

---

## Data Plane Architecture

### Responsibilities

The `MQTTDataPlane` class manages the high-throughput channel for inference results and system metrics.

**Diagram: Data Plane Message Flow**

### Detection Message Format

Detection messages include:

- **Timestamp** (ISO 8601 format)
- **Frame number**
- **Detections array** with bounding boxes, confidence scores, class names
- **Inference latency** (milliseconds)
- **Source information** (stream URL, resolution)

The `compose_detection_message()` method in `data/plane.py` formats predictions from the inference pipeline into JSON for MQTT publishing.

**Sources:** [adeline/CLAUDE.md33-37](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L33-L37) [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py)

### Performance Characteristics

The data plane is optimized for throughput:

- **QoS 0** eliminates acknowledgment overhead
- **Fire-and-forget** publishing prevents backpressure
- **No message persistence** reduces broker memory usage
- **Concurrent publishing** to multiple topics (detections, metrics, frames)

At 30 FPS with 10 detections per frame, the data plane publishes approximately 300 messages/second. QoS 0 ensures this high rate does not impact control plane responsiveness.

**Sources:** [adeline/DESIGN.md12-14](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L12-L14)

---

## Topic Structure and Message Flow

### Topic Hierarchy

The system uses a hierarchical topic structure that separates control and data domains:

```
inference/
├── control/              # QoS 1 - Reliable
│   ├── commands          # Subscribe: Control plane receives commands
│   └── status            # Publish: Control plane sends status updates
│
└── data/                 # QoS 0 - Performance
    ├── detections        # Publish: Detection results
    ├── metrics           # Publish: System metrics (FPS, latency)
    └── full_frames       # Publish: Optional full frame images
```

This structure enables:

1. **Selective subscriptions** - monitors can subscribe only to data topics
2. **Access control** - different credentials for control vs data
3. **Topic-level monitoring** - track control vs data message rates independently

**Sources:** [adeline/CLAUDE.md127-130](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L127-L130)

### Bi-directional Flow

**Diagram: Control and Data Plane Message Sequence**

**Sources:** Synthesized from [adeline/CLAUDE.md23-37](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L23-L37) and high-level architecture diagrams

---

## QoS Strategy and Trade-offs

### QoS Level Comparison

|QoS|Guarantee|Broker Overhead|Latency|Use Case|
|---|---|---|---|---|
|**0**|At-most-once|Minimal|Lowest|High-frequency data streams|
|**1**|At-least-once|Moderate|Moderate|Control commands, status|
|**2**|Exactly-once|High|Highest|Not used (overkill)|

### Control Plane: QoS 1 Justification

The control plane uses QoS 1 for:

1. **Command reliability** - A `stop` command must not be lost
2. **Status consistency** - External systems need accurate pipeline state
3. **Idempotency** - Commands like `pause` can be safely retried if duplicate delivery occurs

The moderate latency overhead (typically <10ms) is acceptable for low-frequency control operations.

### Data Plane: QoS 0 Justification

The data plane uses QoS 0 for:

1. **Throughput** - No acknowledgment delays enable 30+ FPS publishing
2. **Temporal locality** - Missing one detection frame does not impact downstream consumers; the next frame arrives in 33ms
3. **Broker efficiency** - No message persistence reduces memory pressure
4. **Backpressure avoidance** - Slow subscribers do not block the publisher

Occasional message loss (typically <0.1% in stable networks) is acceptable because:

- Detection data is **time-series** - individual points are less valuable than trends
- Monitoring systems use **aggregation** (e.g., detections per second, not per frame)
- Real-time visualization **drops frames** anyway to match display refresh rates

**Sources:** [adeline/CLAUDE.md102-104](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L102-L104) [adeline/DESIGN.md12-14](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L12-L14)

---

## Implementation Details

### Control Plane Class Structure

The `MQTTControlPlane` class ([adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)) provides:

**Key Methods:**

- `connect()` - Establish MQTT connection with QoS 1 subscription
- `disconnect()` - Clean disconnect from broker
- `publish_status(status_dict)` - Publish status updates with QoS 1
- `_on_message()` - Internal callback for command dispatch

**Callback Registration:** Callbacks are registered during initialization:

```
# Example from controller integration
control_plane = MQTTControlPlane(
    on_stop=self.stop,
    on_pause=self.pause,
    on_resume=self.resume,
    on_status=self.get_status,
    on_metrics=self.get_metrics,
    on_toggle_crop=self.toggle_crop,
    on_stabilization_stats=self.get_stabilization_stats
)
```

**Sources:** [adeline/control/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/control/plane.py)

### Data Plane Class Structure

The `MQTTDataPlane` class ([adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py)) provides:

**Key Methods:**

- `connect()` - Establish MQTT connection (no subscriptions needed)
- `disconnect()` - Clean disconnect from broker
- `publish_detection(prediction)` - Publish detection with QoS 0
- `publish_metrics(metrics_dict)` - Publish metrics with QoS 0
- `publish_full_frame(frame_data)` - Optional full frame publishing
- `compose_detection_message(prediction)` - Format prediction into JSON

**Multi-Sink Integration:**

The data plane is integrated into the inference pipeline via the `create_mqtt_sink()` factory ([adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py)):

```
# Example from controller
from inference.core.interfaces.stream.sinks import multi_sink

pipeline.on_prediction = multi_sink(
    create_mqtt_sink(self.data_plane, logger),
    create_visualization_sink(...)
)
```

The multi-sink pattern ([adeline/CLAUDE.md113-121](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L113-L121)) routes each prediction to multiple destinations without modifying the pipeline.

**Sources:** [adeline/data/plane.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/plane.py) [adeline/data/sinks.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/data/sinks.py)

---

## Integration with Pipeline Controller

### Controller Orchestration

The `InferencePipelineController` ([adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py)) acts as the integration point, orchestrating both planes:

**Diagram: Controller Integration of Control and Data Planes**

### Initialization Sequence

The controller follows a strict initialization order:

1. **Load configuration** from `config.yaml` and `.env`
2. **Disable unused models** via `disable_models_from_config()` (see [Initialization Sequence](https://deepwiki.com/care-foundation/kata-inference-251021-clean2/3.4-initialization-sequence))
3. **Import inference module** (now safe after model disabling)
4. **Instantiate control plane** with callback registry
5. **Instantiate data plane** for publishing
6. **Create inference pipeline** with multi-sink integration
7. **Connect both planes** to MQTT broker
8. **Register signal handlers** for graceful shutdown
9. **Start pipeline** to begin processing

This sequence ensures both planes are ready before the first frame is processed, preventing race conditions where detections arrive before the data plane is connected.

**Sources:** [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py) [adeline/CLAUDE.md44-49](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L44-L49)

### Graceful Shutdown

When a `stop` command is received or a signal (SIGINT/SIGTERM) is caught:

1. Control plane invokes `controller.stop()`
2. Controller stops the inference pipeline (no new frames)
3. Data plane flushes any pending messages
4. Both planes disconnect from broker
5. Controller publishes final status update
6. Process exits cleanly

The control plane's QoS 1 guarantee ensures the final status message is delivered before disconnect.

**Sources:** [adeline/app/controller.py](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/app/controller.py) [adeline/CLAUDE.md39-42](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L39-L42)

---

## Summary

The control/data plane separation pattern provides:

✅ **Reliability for control operations** - QoS 1 ensures commands are delivered ✅ **Performance for data streams** - QoS 0 maximizes throughput without latency ✅ **Independent scaling** - Control and data planes can be monitored/tuned separately ✅ **Clear separation of concerns** - Each plane has a single, well-defined responsibility ✅ **Flexible integration** - New data consumers can subscribe without affecting control

This architecture demonstrates the "complexity by design" principle ([adeline/DESIGN.md](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md)): the system's complexity is managed through careful architectural choices (dual planes, QoS strategy, topic structure) rather than complicated code. Each component is simple and focused, with complexity emerging from their orchestrated interaction.

**Sources:** [adeline/DESIGN.md1-22](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/DESIGN.md#L1-L22) [adeline/CLAUDE.md21-104](https://github.com/care-foundation/kata-inference-251021-clean2/blob/9a713ffb/adeline/CLAUDE.md#L21-L104)