# Log Event Patterns

Relevant source files

- [adeline/logging.py](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py)
- [control/plane.py](https://github.com/acare7/kata-inference-251021-clean4/blob/master/control/plane.py)
- [data/plane.py](https://github.com/acare7/kata-inference-251021-clean4/blob/master/data/plane.py)
- [inference/stabilization/core.py](https://github.com/acare7/kata-inference-251021-clean4/blob/master/inference/stabilization/core.py)

## Purpose and Scope

This document describes the common log event patterns used throughout the Adeline system. Each pattern is implemented as a helper function that encodes domain knowledge and ensures consistent schemas across components.

**Scope:**

- Helper function reference and usage examples
- Event schemas by architectural component
- Common logging patterns and best practices

**For related topics:**

- Trace context propagation, see [Structured Logging Design](https://deepwiki.com/acare7/kata-inference-251021-clean4/7.1-structured-logging-design)
- Production query examples, see [Production Queries](https://deepwiki.com/acare7/kata-inference-251021-clean4/7.3-production-queries)

---

## Helper Functions Overview

The logging system provides helper functions for common event types:

|Function|Component|Purpose|
|---|---|---|
|`log_mqtt_command()`|Control Plane|MQTT command reception|
|`log_mqtt_publish()`|Data Plane|MQTT message publishing|
|`log_pipeline_metrics()`|Inference Pipeline|FPS, latency, throughput metrics|
|`log_stabilization_stats()`|Stabilization|Multi-object tracking statistics|
|`log_error_with_context()`|All|Errors with full architectural context|

**Design Principle:** Helper functions encode **architectural knowledge** - they automatically include component identifiers, event types, and trace context.

**Sources:** [adeline/logging.py213-407](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py#L213-L407)

---

## Control Plane Events

### MQTT Command Reception

**Helper Function:**

```python
def log_mqtt_command(
    logger: logging.Logger,
    command: str,
    topic: str,
    payload: Optional[Dict[str, Any]] = None,
    trace_id: Optional[str] = None
) -> None
```

**Usage Example:**

```python
from adeline.logging import log_mqtt_command

# In MQTTControlPlane._on_message()
command_data = json.loads(msg.payload)
command = command_data.get('command')

log_mqtt_command(
    logger,
    command=command,
    topic=msg.topic,
    payload=command_data
)
```

**Output Schema:**

```json
{
  "timestamp": "2025-10-22T16:30:45.123456",
  "level": "INFO",
  "logger": "adeline.control.plane",
  "message": "📥 Comando recibido: pause",
  "component": "control_plane",
  "command": "pause",
  "mqtt_topic": "inference/control/commands",
  "trace_id": "cmd-pause-abc123",
  "payload": {"command": "pause"}
}
```

**Key Fields:**

- `component`: Always `"control_plane"`
- `command`: Command name (pause, resume, stop, etc.)
- `mqtt_topic`: MQTT topic where command was received
- `trace_id`: Automatically injected from context if not provided
- `payload`: Full command payload (optional)

**Sources:** [adeline/logging.py217-244](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py#L217-L244) [control/plane.py115-120](https://github.com/acare7/kata-inference-251021-clean4/blob/master/control/plane.py#L115-L120)

---

## Data Plane Events

### MQTT Message Publishing

**Helper Function:**

```python
def log_mqtt_publish(
    logger: logging.Logger,
    topic: str,
    qos: int,
    payload_size: int,
    success: bool = True,
    error_code: Optional[int] = None,
    num_detections: Optional[int] = None,
    component: str = "data_plane",
) -> None
```

**Usage Example:**

```python
from adeline.logging import log_mqtt_publish

# In MQTTDataPlane.publish()
payload = json.dumps(detection_data)
result = self.client.publish(topic, payload, qos=0)

log_mqtt_publish(
    logger,
    topic=topic,
    qos=0,
    payload_size=len(payload),
    success=(result.rc == mqtt.MQTT_ERR_SUCCESS),
    num_detections=len(detection_data["detections"])
)
```

**Output Schema (Success):**

```json
{
  "timestamp": "2025-10-22T16:30:45.234567",
  "level": "DEBUG",
  "logger": "adeline.data.plane",
  "message": "📤 Mensaje publicado a inference/data/detections",
  "component": "data_plane",
  "mqtt_topic": "inference/data/detections",
  "qos": 0,
  "payload_size_bytes": 1024,
  "success": true,
  "num_detections": 3
}
```

**Output Schema (Error):**

```json
{
  "timestamp": "2025-10-22T16:30:45.234567",
  "level": "WARNING",
  "logger": "adeline.data.plane",
  "message": "⚠️ Error publicando a inference/data/detections",
  "component": "data_plane",
  "mqtt_topic": "inference/data/detections",
  "qos": 0,
  "payload_size_bytes": 1024,
  "success": false,
  "mqtt_error_code": 4
}
```

**Key Fields:**

- `component`: Component identifier (default: `"data_plane"`)
- `mqtt_topic`: Destination MQTT topic
- `qos`: QoS level (0, 1, or 2)
- `payload_size_bytes`: Payload size for bandwidth monitoring
- `success`: Whether publish succeeded
- `mqtt_error_code`: MQTT error code (if `success=False`)
- `num_detections`: Number of detections in payload (optional)

**Sources:** [adeline/logging.py247-287](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py#L247-L287) [data/plane.py](https://github.com/acare7/kata-inference-251021-clean4/blob/master/data/plane.py)

---

## Inference Pipeline Events

### Pipeline Metrics

**Helper Function:**

```python
def log_pipeline_metrics(
    logger: logging.Logger,
    fps: float,
    latency_ms: Optional[float] = None,
    frames_processed: Optional[int] = None,
    additional_metrics: Optional[Dict[str, Any]] = None
) -> None
```

**Usage Example:**

```python
from adeline.logging import log_pipeline_metrics

# In InferencePipeline performance monitoring
log_pipeline_metrics(
    logger,
    fps=30.5,
    latency_ms=15.2,
    frames_processed=1000,
    additional_metrics={
        "detection_count": 12,
        "avg_confidence": 0.87
    }
)
```

**Output Schema:**

```json
{
  "timestamp": "2025-10-22T16:30:45.345678",
  "level": "INFO",
  "logger": "adeline.inference.pipeline",
  "message": "📊 Pipeline metrics: 30.50 FPS",
  "component": "inference_pipeline",
  "metrics": {
    "fps": 30.5,
    "latency_ms": 15.2,
    "frames_processed": 1000,
    "detection_count": 12,
    "avg_confidence": 0.87
  }
}
```

**Key Fields:**

- `component`: Always `"inference_pipeline"`
- `metrics`: Nested object containing all metrics
  - `fps`: Frames per second (required)
  - `latency_ms`: Processing latency in milliseconds (optional)
  - `frames_processed`: Total frames processed (optional)
  - Additional fields from `additional_metrics` parameter

**Use Cases:**

- Real-time performance monitoring
- Aggregate FPS analysis across time windows
- Latency trending and alerting
- Detection throughput analysis

**Sources:** [adeline/logging.py290-323](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py#L290-L323)

---

## Stabilization Events

### Multi-Object Tracking Statistics

**Helper Function:**

```python
def log_stabilization_stats(
    logger: logging.Logger,
    raw_count: int,
    stabilized_count: int,
    active_tracks: int,
    total_confirmed: int = 0,
    total_removed: int = 0,
    source_id: int = 0,
    component: str = "stabilization",
) -> None
```

**Usage Example:**

```python
from adeline.logging import log_stabilization_stats

# In TemporalHysteresisStabilizer.update_tracks()
log_stabilization_stats(
    logger,
    raw_count=len(raw_detections),
    stabilized_count=len(stabilized_detections),
    active_tracks=len(self.active_tracks),
    total_confirmed=self.total_confirmed,
    total_removed=self.total_removed,
    source_id=source_id
)
```

**Output Schema:**

```json
{
  "timestamp": "2025-10-22T16:30:45.456789",
  "level": "DEBUG",
  "logger": "adeline.inference.stabilization.core",
  "message": "Stabilization processed: 12 raw → 8 stabilized (active_tracks=3)",
  "component": "stabilization",
  "source_id": 0,
  "stabilization": {
    "raw_count": 12,
    "stabilized_count": 8,
    "active_tracks": 3,
    "total_confirmed": 45,
    "total_removed": 12
  }
}
```

**Key Fields:**

- `component`: Component identifier (default: `"stabilization"`)
- `source_id`: Video source identifier (for multi-camera setups)
- `stabilization`: Nested object containing tracking stats
  - `raw_count`: Raw detections in current frame
  - `stabilized_count`: Stabilized detections emitted
  - `active_tracks`: Currently active tracks
  - `total_confirmed`: Cumulative confirmed tracks
  - `total_removed`: Cumulative removed tracks

**Use Cases:**

- Stabilization effectiveness analysis (raw vs stabilized ratio)
- Track lifecycle monitoring (creation/removal rates)
- Multi-object tracking performance tuning

**Sources:** [adeline/logging.py326-364](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py#L326-L364) [inference/stabilization/core.py](https://github.com/acare7/kata-inference-251021-clean4/blob/master/inference/stabilization/core.py)

---

## Error Events

### Errors with Full Context

**Helper Function:**

```python
def log_error_with_context(
    logger: logging.Logger,
    message: str,
    exception: Optional[Exception] = None,
    component: str = "unknown",
    event: Optional[str] = None,
    trace_id: Optional[str] = None,
    **kwargs: Any
) -> None
```

**Usage Example:**

```python
from adeline.logging import log_error_with_context

# In MQTTControlPlane.connect()
try:
    self.client.connect(self.broker_host, self.broker_port)
except Exception as e:
    log_error_with_context(
        logger,
        "MQTT connection failed",
        exception=e,
        component="control_plane",
        event="mqtt_connect",
        broker_host=self.broker_host,
        broker_port=self.broker_port,
        timeout=timeout
    )
```

**Output Schema:**

```json
{
  "timestamp": "2025-10-22T16:30:45.567890",
  "level": "ERROR",
  "logger": "adeline.control.plane",
  "message": "MQTT connection failed: Connection refused",
  "component": "control_plane",
  "event": "mqtt_connect",
  "trace_id": "cmd-pause-abc123",
  "error_type": "ConnectionRefusedError",
  "error_message": "Connection refused",
  "broker_host": "localhost",
  "broker_port": 1883,
  "timeout": 10,
  "exc_info": "Traceback (most recent call last):\n  ..."
}
```

**Key Fields:**

- `component`: Component where error occurred
- `event`: Event that triggered the error (optional)
- `trace_id`: Correlation ID (automatically injected from context)
- `error_type`: Exception class name
- `error_message`: Exception message
- `exc_info`: Full traceback (Python logging feature)
- Additional context fields from `**kwargs` (broker_host, topic, config values, etc.)

**Use Cases:**

- Error debugging with full architectural context
- Error rate analysis by component
- Root cause analysis via trace correlation
- Alert generation with actionable context

**Sources:** [adeline/logging.py367-406](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py#L367-L406)

---

## Best Practices

### 1. Use Helper Functions Instead of Raw Logging

**❌ Avoid:**

```python
logger.info("Command received", extra={
    "command": "pause",
    "topic": "inference/control/commands"
})
```

**✅ Prefer:**

```python
log_mqtt_command(logger, command="pause", topic="inference/control/commands")
```

**Rationale:** Helper functions ensure consistent schemas and automatically inject component/trace context.

---

### 2. Always Include Component Identifier

**❌ Avoid:**

```python
logger.error("Processing failed", extra={"error": str(e)})
```

**✅ Prefer:**

```python
log_error_with_context(logger, "Processing failed", exception=e, component="data_plane")
```

**Rationale:** Component identifiers enable filtering by architectural boundary (e.g., all Control Plane errors).

---

### 3. Leverage Trace Context Propagation

**❌ Avoid:**

```python
# Manually passing trace_id everywhere
def process_command(command: str, trace_id: str):
    logger.info("Processing", extra={"trace_id": trace_id})
    execute_action(command, trace_id)

def execute_action(command: str, trace_id: str):
    logger.info("Executing", extra={"trace_id": trace_id})
```

**✅ Prefer:**

```python
# Use context manager once
with trace_context(f"cmd-{command}-{uuid4().hex[:8]}"):
    logger.info("Processing")  # trace_id auto-injected
    execute_action(command)

def execute_action(command: str):
    logger.info("Executing")  # trace_id auto-injected
```

**Rationale:** Context manager propagates trace_id through entire call stack without explicit parameter passing.

---

### 4. Include Actionable Context in Errors

**❌ Avoid:**

```python
logger.error("Connection failed")
```

**✅ Prefer:**

```python
log_error_with_context(
    logger,
    "MQTT connection failed",
    exception=e,
    component="control_plane",
    broker_host=config.MQTT_BROKER,
    broker_port=config.MQTT_PORT,
    retry_count=3
)
```

**Rationale:** Actionable context enables rapid troubleshooting (Is broker running? Port blocked? Wrong credentials?).

---

### 5. Use Semantic Event Types

**❌ Avoid:**

```python
logger.info("Track created", extra={"track_id": 123})
```

**✅ Prefer:**

```python
logger.info("Track created", extra={
    "event_type": "track_created",
    "track_id": 123,
    "component": "stabilization"
})
```

**Rationale:** Event types enable semantic queries (e.g., all track lifecycle events: `track_created`, `track_updated`, `track_lost`).

**Sources:** [adeline/logging.py](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py)

---

## Event Schema Summary

### By Component

**Control Plane:**

```json
{
  "component": "control_plane",
  "command": "pause",
  "mqtt_topic": "inference/control/commands",
  "trace_id": "cmd-pause-abc123"
}
```

**Data Plane:**

```json
{
  "component": "data_plane",
  "mqtt_topic": "inference/data/detections",
  "qos": 0,
  "payload_size_bytes": 1024,
  "num_detections": 3
}
```

**Inference Pipeline:**

```json
{
  "component": "inference_pipeline",
  "metrics": {
    "fps": 30.5,
    "latency_ms": 15.2
  }
}
```

**Stabilization:**

```json
{
  "component": "stabilization",
  "stabilization": {
    "raw_count": 12,
    "stabilized_count": 8,
    "active_tracks": 3
  }
}
```

**Errors (All Components):**

```json
{
  "component": "control_plane",
  "event": "mqtt_connect",
  "error_type": "ConnectionRefusedError",
  "error_message": "Connection refused",
  "trace_id": "cmd-pause-abc123"
}
```

---

## Summary

Log event patterns in Adeline are:

1. **Component-Specific** - Each pattern reflects an architectural boundary
2. **Schema-Consistent** - Helper functions enforce consistent field naming
3. **Trace-Aware** - Automatic trace_id injection from context
4. **Actionable** - Errors include full context for rapid debugging
5. **Queryable** - Structured schemas enable `jq` queries without parsing

**Design Philosophy:** Event patterns are **vocabulary for observability** - they encode architectural knowledge and enable powerful runtime queries.

**Sources:** [adeline/logging.py213-407](https://github.com/acare7/kata-inference-251021-clean4/blob/master/adeline/logging.py#L213-L407)
