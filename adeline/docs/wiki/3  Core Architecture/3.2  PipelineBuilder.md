# PipelineBuilder

Relevant source files

- [adeline/CLAUDE.md](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/CLAUDE.md)
- [adeline/app/builder.py](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py)

## Purpose and Scope

TheÂ `PipelineBuilder`Â class implements the Builder pattern to construct and assemble all components required for the inference pipeline. It orchestrates the creation of handlers, sinks, and theÂ `InferencePipeline`Â itself by delegating to specialized factories. This page describes the construction process, dependency injection flow, and how the builder maintains separation of concerns.

For information about the controller that uses this builder, seeÂ [InferencePipelineController](https://deepwiki.com/acare7/kata-inference-251021-clean4/3.1-inferencepipelinecontroller). For details on the factories that PipelineBuilder delegates to, seeÂ [Factory Pattern System](https://deepwiki.com/acare7/kata-inference-251021-clean4/3.3-factory-pattern-system).

**Sources:**Â [adeline/app/builder.py1-18](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L1-L18)Â [adeline/CLAUDE.md68-88](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/CLAUDE.md#L68-L88)

---

## Overview

TheÂ `PipelineBuilder`Â centralizes all component construction logic that was previously scattered across the controller. Its responsibilities are:

- Orchestrate factory calls to create components
- Build inference handlers viaÂ `InferenceHandlerFactory`
- Build sinks viaÂ `SinkFactory`
- Conditionally wrap sinks with stabilization viaÂ `StrategyFactory`
- Assemble the finalÂ `InferencePipeline`Â (standard or custom logic mode)

The builder doesÂ **not**Â manage lifecycle, state, or control flow â€” those remain the responsibility ofÂ `InferencePipelineController`. This separation follows the principle: "Builder orchestrates, Factories construct, Controller manages."

**Sources:**Â [adeline/app/builder.py1-18](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L1-L18)Â [adeline/CLAUDE.md56-88](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/CLAUDE.md#L56-L88)

---

## Class Structure



```mermaid
classDiagram
  class PipelineBuilder {
    - PipelineConfig config
    - Optional<Stabilizer> stabilizer
    + init(config)
    + build_inference_handler() : Tuple
    + build_sinks(data_plane, roi_state, handler) : List
    + wrap_sinks_with_stabilization(sinks) : List
    + build_pipeline(handler, sinks, watchdog, status_handlers) : InferencePipeline
  }

  class PipelineConfig {
    + str MODEL_ID
    + str RTSP_URL
    + int MAX_FPS
    + str ROI_MODE
    + str STABILIZATION_MODE
    + str API_KEY
  }

  class InferenceHandlerFactory {
    + create(config) : Tuple
  }

  class SinkFactory {
    + create_sinks(config, data_plane, roi_state, handler) : List
  }

  class StrategyFactory {
    + create_stabilization_strategy(config) : Stabilizer
  }

  class InferencePipeline {
    + init(...)
    + init_with_custom_logic(...)
  }

  PipelineBuilder ..> PipelineConfig : uses
  PipelineBuilder ..> InferenceHandlerFactory : delegates to
  PipelineBuilder ..> SinkFactory : delegates to
  PipelineBuilder ..> StrategyFactory : delegates to
  PipelineBuilder ..> InferencePipeline : constructs
```

**PipelineBuilder Method Responsibilities**

|Method|Purpose|Factory Used|Returns|
|---|---|---|---|
|`build_inference_handler()`|Create handler for ROI processing|`InferenceHandlerFactory`|`(handler, roi_state)`|
|`build_sinks()`|Create output sinks (MQTT, viz, ROI update)|`SinkFactory`|`List[Callable]`|
|`wrap_sinks_with_stabilization()`|Wrap first sink with stabilizer (if enabled)|`StrategyFactory`|`List[Callable]`Â (new)|
|`build_pipeline()`|Assemble final pipeline|None (direct construction)|`InferencePipeline`|

**Sources:**Â [adeline/app/builder.py41-69](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L41-L69)Â [adeline/app/builder.py71-208](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L71-L208)

---

## Four-Phase Construction Process

TheÂ `PipelineBuilder`Â executes a four-phase construction process, typically orchestrated byÂ `InferencePipelineController.setup()`:


```mermaid
sequenceDiagram
    participant Controller as InferencePipelineController
    participant Builder as PipelineBuilder
    participant HF as InferenceHandlerFactory
    participant SF as SinkFactory
    participant STF as StrategyFactory
    participant Pipeline as InferencePipeline

    Note over Controller,Builder: Phase 1: Build Handler
    Controller->>Builder: __init__(config)
    Controller->>Builder: build_inference_handler()
    Builder->>HF: create(config)
    HF-->>Builder: (handler, roi_state)
    Builder-->>Controller: (handler, roi_state)

    Note over Controller,Builder: Phase 2: Build Sinks
    Controller->>Builder: build_sinks(data_plane, roi_state, handler)
    Builder->>SF: create_sinks(config, data_plane, roi_state, handler)
    SF-->>Builder: [mqtt_sink, roi_sink, viz_sink]
    Builder-->>Controller: sinks

    Note over Controller,Builder: Phase 3: Wrap Stabilization
    Controller->>Builder: wrap_sinks_with_stabilization(sinks)
    alt STABILIZATION_MODE != 'none'
        Builder->>STF: create_stabilization_strategy(config)
        STF-->>Builder: stabilizer
        Builder-->>Builder: wrap first sink
        Builder-->>Controller: [stabilized_sink, roi_sink, viz_sink]
    else STABILIZATION_MODE == 'none'
        Builder-->>Controller: sinks (unchanged)
    end

    Note over Controller,Pipeline: Phase 4: Build Pipeline
    Controller->>Builder: build_pipeline(handler, sinks, watchdog, status_handlers)
    alt ROI_MODE == 'none'
        Builder->>Pipeline: init(model_id, ...)
    else ROI_MODE in ['adaptive', 'fixed']
        Builder->>Pipeline: init_with_custom_logic(on_video_frame=handler, ...)
    end
    Pipeline-->>Builder: pipeline
    Builder-->>Controller: pipeline
```

**Sources:**Â [adeline/app/builder.py41-208](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L41-L208)

---

## Phase 1: Build Inference Handler

TheÂ `build_inference_handler()`Â method delegates toÂ `InferenceHandlerFactory`Â to create the appropriate handler based onÂ `config.ROI_MODE`.

```
# From app/builder.py:71-83
def build_inference_handler(self) -> Tuple[BaseInferenceHandler, Optional[Any]]:
    """
    Construye inference handler segÃºn configuraciÃ³n.
    
    Returns:
        (handler, roi_state)
            - handler: BaseInferenceHandler
            - roi_state: ROIState | FixedROIState | None
    """
    logger.info("ðŸ”§ Building inference handler...")
    return InferenceHandlerFactory.create(self.config)
```

**Handler Selection Logic**

|`config.ROI_MODE`|Handler Type|State Type|Factory Method|
|---|---|---|---|
|`'none'`|`StandardInferenceHandler`|`None`|`InferenceHandlerFactory.create()`|
|`'adaptive'`|`AdaptiveInferenceHandler`|`ROIState`|`InferenceHandlerFactory.create()`|
|`'fixed'`|`FixedROIInferenceHandler`|`FixedROIState`|`InferenceHandlerFactory.create()`|

The returnedÂ `roi_state`Â is later passed toÂ `build_sinks()`Â to enable ROI update sinks when applicable.

**Sources:**Â [adeline/app/builder.py71-83](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L71-L83)Â [adeline/CLAUDE.md105-113](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/CLAUDE.md#L105-L113)

---

## Phase 2: Build Sinks

TheÂ `build_sinks()`Â method delegates toÂ `SinkFactory`Â to create a priority-ordered list of output sinks.

```
# From app/builder.py:85-110
def build_sinks(
    self,
    data_plane: Any,  # MQTTDataPlane
    roi_state: Optional[Any] = None,
    inference_handler: Optional[BaseInferenceHandler] = None,
) -> List[Callable]:
    """
    Construye sinks segÃºn configuraciÃ³n.
    
    Args:
        data_plane: MQTTDataPlane
        roi_state: ROIState | FixedROIState | None
        inference_handler: BaseInferenceHandler | None
    
    Returns:
        Lista de sinks para multi_sink()
    """
    logger.info("ðŸ”§ Building sinks...")
    return SinkFactory.create_sinks(
        config=self.config,
        data_plane=data_plane,
        roi_state=roi_state,
        inference_handler=inference_handler,
    )
```

**Sink Priority Order**

TheÂ `SinkFactory`Â uses a registry pattern with explicit priorities (seeÂ [SinkFactory](https://deepwiki.com/acare7/kata-inference-251021-clean4/3.3.2-sinkfactory)):

|Priority|Sink Type|Condition|Purpose|
|---|---|---|---|
|1|MQTT Sink|Always|Publish detections to MQTT broker|
|50|ROI Update Sink|`roi_state is not None`|Update adaptive ROI state|
|100|Visualization Sink|`config.ENABLE_DISPLAY`|OpenCV display window|

The returned list is ordered by priority (lowest first), which is important because stabilization wrapping (Phase 3) assumes the MQTT sink is first.

**Sources:**Â [adeline/app/builder.py85-110](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L85-L110)

---

## Phase 3: Wrap Stabilization

TheÂ `wrap_sinks_with_stabilization()`Â method conditionally wraps the first sink (MQTT) with a stabilization decorator.

```
# From app/builder.py:112-151
def wrap_sinks_with_stabilization(self, sinks: List[Callable]) -> List[Callable]:
    """
    Wrappea primer sink (MQTT) con stabilization si estÃ¡ habilitado.
    
    Args:
        sinks: Lista de sinks (NO se modifica)
    
    Returns:
        NUEVA lista con primer sink wrappeado
    
    Side effects:
        - Setea self.stabilizer si stabilization habilitado
    
    Note:
        Functional purity: No modifica input, retorna nuevo array.
    """
    if self.config.STABILIZATION_MODE == 'none':
        logger.info("ðŸ”² Stabilization wrapper: SKIPPED (mode=none)")
        self.stabilizer = None
        return sinks
    
    logger.info("ðŸ”§ Wrapping sink with stabilization...")
    
    from ..inference.stabilization import create_stabilization_sink
    
    # Crear stabilizer usando factory
    self.stabilizer = StrategyFactory.create_stabilization_strategy(self.config)
    
    # Wrappear primer sink (MQTT sink)
    mqtt_sink = sinks[0]
    stabilized_sink = create_stabilization_sink(
        stabilizer=self.stabilizer,
        downstream_sink=mqtt_sink,
    )
    
    # NUEVO array con wrapped sink (immutable operation)
    new_sinks = [stabilized_sink] + sinks[1:]
    
    logger.info(f"âœ… Stabilization wrapper: {self.config.STABILIZATION_MODE.upper()}")
    return new_sinks
```

**Key Design Decisions**

1. **Immutability**: The method returns aÂ **new list**Â rather than modifying the input. This follows functional programming principles and prevents side effects:Â `new_sinks = [stabilized_sink] + sinks[1:]`
    
2. **First Sink Assumption**: Only the MQTT sink (priority 1, index 0) gets wrapped. ROI update and visualization sinks receive raw detections.
    
3. **Factory Delegation**: The stabilizer itself is created byÂ `StrategyFactory.create_stabilization_strategy()`, which selects betweenÂ `NoOpStabilizer`Â andÂ `TemporalHysteresisStabilizer`Â based onÂ `config.STABILIZATION_MODE`.
    
4. **State Preservation**: The createdÂ `stabilizer`Â is stored inÂ `self.stabilizer`Â for later access (e.g., for theÂ `stabilization_stats`Â MQTT command).
    

**Sources:**Â [adeline/app/builder.py112-151](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L112-L151)

---

## Phase 4: Build Pipeline

TheÂ `build_pipeline()`Â method assembles the finalÂ `InferencePipeline`, selecting betweenÂ **standard mode**Â (model ID-based) orÂ **custom logic mode**Â (handler-based).

```
# From app/builder.py:153-208
def build_pipeline(
    self,
    inference_handler: BaseInferenceHandler,
    sinks: List[Callable],
    watchdog: BasePipelineWatchDog,
    status_update_handlers: List[Callable],
) -> InferencePipeline:
    """
    Construye InferencePipeline (standard o custom logic).
    """
    logger.info("ðŸ”§ Building InferencePipeline...")
    
    # ComposiciÃ³n de sinks
    on_prediction = partial(multi_sink, sinks=sinks)
    
    # Standard vs Custom Logic
    if self.config.ROI_MODE == 'none':
        # Standard pipeline (model_id based)
        pipeline = InferencePipeline.init(
            max_fps=self.config.MAX_FPS,
            model_id=self.config.MODEL_ID,
            video_reference=self.config.RTSP_URL,
            on_prediction=on_prediction,
            api_key=self.config.API_KEY,
            watchdog=watchdog,
            status_update_handlers=status_update_handlers,
        )
    else:
        # Custom logic pipeline (ROI based)
        pipeline = InferencePipeline.init_with_custom_logic(
            video_reference=self.config.RTSP_URL,
            on_video_frame=inference_handler,
            on_prediction=on_prediction,
            max_fps=self.config.MAX_FPS,
            watchdog=watchdog,
            status_update_handlers=status_update_handlers,
        )
    
    logger.info("âœ… Pipeline created successfully")
    return pipeline
```

**Pipeline Mode Selection**



```mermaid
flowchart TD
    Build[build_pipeline]
    Check{config.ROI_MODE == 'none'?}

    Standard[InferencePipeline.init - Standard Mode]
    Custom[InferencePipeline.init_with_custom_logic - Custom Logic Mode]

    Details1[Uses model_id directly; Full frame inference; No ROI processing]
    Details2[Uses on_video_frame=handler; Handler controls ROI cropping; Handler transforms coordinates]

    Compose[Compose sinks with partial multi_sink sinks=sinks]
    Return[Return InferencePipeline]

    Build --> Check
    Check -- Yes --> Standard
    Check -- No --> Custom

    Standard --> Details1
    Custom --> Details2

    Details1 --> Compose
    Details2 --> Compose

    Compose --> Return
```


**Comparison**

|Aspect|Standard Mode (`ROI_MODE='none'`)|Custom Logic Mode (`ROI_MODE='adaptive'`Â orÂ `'fixed'`)|
|---|---|---|
|Constructor|`InferencePipeline.init()`|`InferencePipeline.init_with_custom_logic()`|
|Inference Control|UsesÂ `model_id`Â parameter|UsesÂ `on_video_frame=handler`Â parameter|
|Frame Processing|Full frame â†’ YOLO model|Handler crops â†’ YOLO model â†’ Handler transforms|
|ROI Support|No|Yes|
|Use Case|Simple full-frame detection|Adaptive/fixed ROI optimization|

**Sink Composition**

Both modes useÂ `functools.partial()`Â to compose the multi-sink:

```
on_prediction = partial(multi_sink, sinks=sinks)
```

This creates a callable that will invoke all sinks in order when predictions are ready. TheÂ `multi_sink`Â function is provided by the inference library.

**Sources:**Â [adeline/app/builder.py153-208](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L153-L208)Â [adeline/CLAUDE.md105-113](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/CLAUDE.md#L105-L113)

---

## Dependency Injection Flow

The following diagram shows how dependencies flow through the builder to create the final pipeline:


```mermaid
flowchart TD
  C[PipelineConfig injected]
  B[PipelineBuilder init config]
  P1[build_inference_handler]
  HF[InferenceHandlerFactory.create]
  H[handler: BaseInferenceHandler; roi_state: ROIState or None]
  DP[data_plane: MQTTDataPlane injected]
  P2[build_sinks]
  SF[SinkFactory.create_sinks]
  S[sinks: list of callables]
  P3[wrap_sinks_with_stabilization]
  CH{STABILIZATION_MODE != 'none'?}
  STF[StrategyFactory.create_stabilization_strategy]
  WR[create_stabilization_sink]
  NS[new_sinks: list of callables; first sink wrapped]
  NW[sinks unchanged]
  WD[watchdog: BasePipelineWatchDog injected]
  SH[status_update_handlers injected]
  P4[build_pipeline]
  PIPE[InferencePipeline]

  C --> B
  B --> P1
  P1 --> HF
  HF --> H
  H --> P2
  DP --> P2
  P2 --> SF
  SF --> S
  S --> P3
  P3 --> CH

  CH -- Yes --> STF
  CH -- No --> NW

  STF --> WR
  WR --> NS
  NS --> P4
  NW --> P4
  H  --> P4
  WD --> P4
  SH --> P4

  P4 --> PIPE
```

**Injected Dependencies**

The builder receives dependencies fromÂ `InferencePipelineController`Â at different phases:

|Phase|Injected Dependency|Source|Purpose|
|---|---|---|---|
|Constructor|`PipelineConfig`|Controller init|Configuration for all phases|
|Phase 2|`MQTTDataPlane`|Controller setup|MQTT publishing capability|
|Phase 2|`ROIState`|Phase 1 output|ROI update sink creation|
|Phase 2|`BaseInferenceHandler`|Phase 1 output|Handler capability checks|
|Phase 4|`BasePipelineWatchDog`|Controller setup|Metrics collection|
|Phase 4|`List[Callable]`Â (status handlers)|Controller setup|Status callbacks|

**Sources:**Â [adeline/app/builder.py41-208](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L41-L208)

---

## Lazy Loading Pattern

The builder uses theÂ `InferenceLoader`Â pattern to ensure inference modules are loaded correctly:

```
# From app/builder.py:23-27
from ..inference.loader import InferenceLoader

inference_module = InferenceLoader.get_inference()
InferencePipeline = inference_module.InferencePipeline
```

**Why Lazy Loading?**

TheÂ `InferenceLoader.get_inference()`Â method ensuresÂ `disable_models_from_config()`Â runsÂ **before**Â importing inference modules. This prevents unnecessary model downloads when not needed (e.g., during testing or when inference is disabled).

This pattern is enforced by design:

1. All code must importÂ `InferencePipeline`Â throughÂ `InferenceLoader`, not directly
2. The loader handles the disable logic internally
3. Import order is guaranteed by the loader's implementation

For more details, seeÂ [Lazy Loading and Model Management](https://deepwiki.com/acare7/kata-inference-251021-clean4/8.2-lazy-loading-and-model-management).

**Sources:**Â [adeline/app/builder.py23-27](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L23-L27)Â [adeline/CLAUDE.md137-142](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/CLAUDE.md#L137-L142)

---

## Design Principles

### Separation of Concerns

The builder enforces clear boundaries:

- **Controller**: Lifecycle management (start/stop/pause/resume), state transitions
- **Builder**: Component construction, assembly, dependency orchestration
- **Factories**: Component creation logic, configuration interpretation

This separation means:

- Controller code hasÂ **zero knowledge**Â of construction details (model IDs, handler types, etc.)
- Builder code hasÂ **zero knowledge**Â of lifecycle state (running/paused/stopped)
- Factories haveÂ **zero knowledge**Â of how components are assembled



```mermaid
flowchart TD
  C[InferencePipelineController Lifecycle & State]
  B[PipelineBuilder Construction & Assembly]
  F[Factory Layer Component Creation]

  C -->|uses| B
  B -->|delegates to| F
  C -.->|no knowledge of| F
  F -.->|no knowledge of| C
```
**Sources:**Â [adeline/CLAUDE.md56-88](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/CLAUDE.md#L56-L88)Â [adeline/app/builder.py1-18](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L1-L18)

### Immutable Operations

TheÂ `wrap_sinks_with_stabilization()`Â method demonstrates functional purity:

```
# Does NOT modify input
def wrap_sinks_with_stabilization(self, sinks: List[Callable]) -> List[Callable]:
    # ...
    new_sinks = [stabilized_sink] + sinks[1:]  # NEW list
    return new_sinks  # Input unchanged
```

This prevents subtle bugs where modifying a list has unintended side effects on other parts of the system.

**Sources:**Â [adeline/app/builder.py112-151](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L112-L151)

### Factory Delegation

Every component creation is delegated to a specialized factory:

|Component|Factory|Method|
|---|---|---|
|Inference Handler|`InferenceHandlerFactory`|`create(config)`|
|Sinks|`SinkFactory`|`create_sinks(...)`|
|Stabilizer|`StrategyFactory`|`create_stabilization_strategy(config)`|

The builderÂ **never**Â directly instantiates components. This ensures:

- Construction logic is centralized in factories
- Adding new component types only requires factory changes
- Builder logic remains stable across feature additions

**Sources:**Â [adeline/app/builder.py71-151](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L71-L151)

---

## Usage Example

Typical usage fromÂ `InferencePipelineController.setup()`:

```
# 1. Create builder
builder = PipelineBuilder(self.config)

# 2. Build handler (Phase 1)
handler, roi_state = builder.build_inference_handler()

# 3. Build sinks (Phase 2)
sinks = builder.build_sinks(
    data_plane=self.data_plane,
    roi_state=roi_state,
    inference_handler=handler
)

# 4. Wrap stabilization (Phase 3)
if self.config.STABILIZATION_MODE != 'none':
    sinks = builder.wrap_sinks_with_stabilization(sinks)
    self.stabilizer = builder.stabilizer  # Store for commands

# 5. Build pipeline (Phase 4)
self.pipeline = builder.build_pipeline(
    inference_handler=handler,
    sinks=sinks,
    watchdog=self.watchdog,
    status_update_handlers=self.status_update_handlers
)
```

**Sources:**Â [adeline/app/builder.py41-61](https://github.com/acare7/kata-inference-251021-clean4/blob/a0662727/adeline/app/builder.py#L41-L61)